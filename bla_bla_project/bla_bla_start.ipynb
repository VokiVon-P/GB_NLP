{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект Телеграм чат-бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: не забыть залить из DEV ветки!!!\n",
    "# t.me/voki_blabla_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install -U python-telegram-bot\n",
    "# !pip install python-telegram-bot==12.4.2 --upgrade\n",
    "# !pip install -U annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import annoy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as nb_tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_FILE = 'chat.env'\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "RAW_FILE = 'Otvety.txt'\n",
    "ANSWERS_FILE = 'prep_answers.txt'\n",
    "PRODUCT_FILE = 'ProductsDataset.csv'\n",
    "\n",
    "FAST_TEXT_MODEL = './models/ft_model'\n",
    "\n",
    "INDEX_ANSWERS = './models/idx_answers.pkl'\n",
    "INDEX_SHOP = './models/index_shop.pkl'\n",
    "\n",
    "FT_INDEX_BLABLA = './models/ft_index'\n",
    "FT_INDEX_SHOP = './models/ft_index_shop'\n",
    "\n",
    "VECTOR_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка файла с настройками переменных окружения\n",
    "\n",
    "# dotenv_path = os.path.join(os.path.dirname(__file__), '.env')\n",
    "if os.path.exists(ENV_FILE):\n",
    "    load_dotenv(ENV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация анализатора, стоп слов, пунктуации\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    \"\"\" предобработка перед векторизацией \"\"\"\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "#     print(spls)\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "#     print(spls)\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "#     print(spls)\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = os.path.join(DATA_PATH, RAW_FILE)\n",
    "file_answers = os.path.join(DATA_PATH, ANSWERS_FILE)\n",
    "file_product = os.path.join(DATA_PATH, PRODUCT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка ответов болталки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7550926it [00:13, 572144.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# подготовка файло вопрос-ответ\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(file_answers, \"w\", encoding=\"utf8\") as fout:\n",
    "    with open(file_input, \"r\", encoding=\"utf8\") as fin:\n",
    "        for line in tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500000it [24:58, 333.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# подготовка корпуса для обучения векторизатора\n",
    "sentences = []\n",
    "c = 0\n",
    "STOP = 500000\n",
    "\n",
    "with open(file_input, \"r\", encoding=\"utf8\") as fin:\n",
    "    for line in tqdm(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > STOP:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение векторизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 27s, sys: 6.77 s, total: 10min 34s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "modelFT = FastText(sentences=sentences, size=VECTOR_SIZE, min_count=1, window=5)\n",
    "modelFT.save(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка индексов для NN поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1163342it [59:05, 328.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59min 21s, sys: 22.8 s, total: 59min 44s\n",
      "Wall time: 59min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_index = annoy.AnnoyIndex(VECTOR_SIZE ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(file_answers, \"r\", encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        vector_ft = np.zeros(VECTOR_SIZE)\n",
    "        for word in question:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем словарь индексов ответов\n",
    "with open(INDEX_ANSWERS, 'wb') as f:\n",
    "    pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You can't build a loaded index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: You can't build a loaded index"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# строим индекс поиска и сохраняем\n",
    "ft_index.build(25)\n",
    "ft_index.save(FT_INDEX_BLABLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка работы с основной продукцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(FAST_TEXT_MODEL)\n",
    "\n",
    "ft_index = annoy.AnnoyIndex(VECTOR_SIZE, 'angular')\n",
    "ft_index.load(FT_INDEX_BLABLA)\n",
    "\n",
    "with open(INDEX_ANSWERS, 'rb') as f:\n",
    "    index_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                       descrirption  \\\n",
       "0  Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1          Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_data = pd.read_csv(file_product)\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010db51067b04c27b8ad0df0051268d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5378f1cadb8e4ca29b7e785bcdfc74f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35548.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4min 46s, sys: 534 ms, total: 4min 47s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# выберем в качестве негативных вариантов - ответы болталки\n",
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in nb_tqdm(idxs)]\n",
    "# позитивные ответы - из теблицы продукции\n",
    "positive_texts = [\" \".join(val) for val in nb_tqdm(shop_data['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформируем датесет ответов и лейблов\n",
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, stratify=labels,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# парочка классификаторов - на всякий случай\n",
    "lr = LogisticRegression().fit(x_train_vec, y_train)\n",
    "svc = LinearSVC().fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9783841247342311"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820694542877392"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=svc.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2340203it [00:01, 2202233.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# создадим словарь с ключом - слово : значение = idf слова\n",
    "idfs = {v[0]: v[1] for v in tqdm(zip(vectorizer.vocabulary_, vectorizer.idf_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf215c6da1e4f9f82594fc3d774d57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35548.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index_shop = annoy.AnnoyIndex(VECTOR_SIZE ,'angular')\n",
    "\n",
    "midf = np.mean(vectorizer.idf_)\n",
    "\n",
    "index_map_shop = {}\n",
    "counter = 0\n",
    "\n",
    "for i in nb_tqdm(range(len(shop_data))):\n",
    "    n_ft = 0\n",
    "    index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "    vector_ft = np.zeros(VECTOR_SIZE)\n",
    "    for word in shop_data.loc[i, \"text\"]:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    if n_ft > 0:\n",
    "        vector_ft = vector_ft / n_ft\n",
    "    ft_index_shop.add_item(counter, vector_ft)\n",
    "    counter += 1\n",
    "\n",
    "ft_index_shop.build(25)\n",
    "ft_index_shop.save(FT_INDEX_SHOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INDEX_SHOP, \"wb\") as f:\n",
    "    pickle.dump(index_map_shop, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(VECTOR_SIZE)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3083288371562958\n",
      "0.46290239691734314\n"
     ]
    }
   ],
   "source": [
    "TG_token = os.getenv('TG_voki_blabla_bot_token') # Токен API к Telegram\n",
    "\n",
    "updater = Updater(token=TG_token) \n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    update.message.reply_text(f'Добрейшего дня, {update.message.from_user.username}')\n",
    "    \n",
    "\n",
    "def textMessage(update, context):\n",
    "    \n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = svc.predict(vect)\n",
    "    \n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            update.message.reply_text(\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "    if distances[0] > 0.2:\n",
    "        print(distances[0])\n",
    "        update.message.reply_text(text=\"Моя твоя не понимать\")\n",
    "        return\n",
    "    update.message.reply_text(index_map[ft_index_val[0]])\n",
    "    \n",
    "def echo(update, context):\n",
    "    \"\"\"Echo the user message.\"\"\"\n",
    "    update.message.reply_text(update.message.text)\n",
    "\n",
    "\n",
    "# обработчики комманд\n",
    "dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "# dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "\n",
    "# \n",
    "dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, textMessage))\n",
    "# text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "# dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "output_auto_scroll": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
