{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект Телеграм чат-бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: не забыть залить из DEV ветки!!!\n",
    "# t.me/voki_blabla_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# !pip install -U python-telegram-bot\n",
    "# !pip install python-telegram-bot==12.4.2 --upgrade\n",
    "# !pip install -U annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import annoy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm_notebook, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_FILE = 'chat.env'\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "RAW_FILE = 'Otvety.txt'\n",
    "ANSWERS_FILE = 'prep_answers.txt'\n",
    "PRODUCT_FILE = 'ProductsDataset.csv'\n",
    "FAST_TEXT_MODEL = './models/ft_model'\n",
    "INDEX_ANSWERS = './models/idx_answers.pkl'\n",
    "FT_INDEX_FILE = './models/ft_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка файла с настройками переменных окружения\n",
    "\n",
    "# dotenv_path = os.path.join(os.path.dirname(__file__), '.env')\n",
    "if os.path.exists(ENV_FILE):\n",
    "    load_dotenv(ENV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация анализатора, стоп слов, пунктуации\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    \"\"\" предобработка перед векторизацией \"\"\"\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "#     print(spls)\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "#     print(spls)\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "#     print(spls)\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input = os.path.join(DATA_PATH, RAW_FILE)\n",
    "file_answers = os.path.join(DATA_PATH, ANSWERS_FILE)\n",
    "file_product = os.path.join(DATA_PATH, PRODUCT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка ответов болталки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7550926it [00:13, 572144.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# подготовка файло вопрос-ответ\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(file_answers, \"w\", encoding=\"utf8\") as fout:\n",
    "    with open(file_input, \"r\", encoding=\"utf8\") as fin:\n",
    "        for line in tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500000it [24:58, 333.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# подготовка корпуса для обучения векторизатора\n",
    "sentences = []\n",
    "c = 0\n",
    "STOP = 500000\n",
    "\n",
    "with open(file_input, \"r\", encoding=\"utf8\") as fin:\n",
    "    for line in tqdm(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > STOP:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение векторизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 27s, sys: 6.77 s, total: 10min 34s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "modelFT = FastText(sentences=sentences, size=VECTOR_SIZE, min_count=1, window=5)\n",
    "modelFT.save(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка индексов для NN поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1163342it [59:05, 328.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59min 21s, sys: 22.8 s, total: 59min 44s\n",
      "Wall time: 59min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_index = annoy.AnnoyIndex(VECTOR_SIZE ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(file_answers, \"r\", encoding='utf-8') as f:\n",
    "    for line in tqdm(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        vector_ft = np.zeros(VECTOR_SIZE)\n",
    "        for word in question:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем словарь индексов ответов\n",
    "with open(INDEX_ANSWERS, 'wb') as f:\n",
    "    pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 805 ms, total: 1min 37s\n",
      "Wall time: 40.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# строим индекс поиска и сохраняем\n",
    "ft_index.build(25)\n",
    "ft_index.save(FT_INDEX_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка работы с основной продукцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                       descrirption  \\\n",
       "0  Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1          Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_data = pd.read_csv(file_product)\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG_token = os.getenv('TG_voki_blabla_bot_token') # Токен API к Telegram\n",
    "\n",
    "updater = Updater(token=TG_token) \n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
    "    update.message.reply_text(f'Добрейшего дня, {update.message.from_user.username}')\n",
    "    \n",
    "    \n",
    "# def startCommand(bot, update):\n",
    "#     bot.send_message(chat_id=update.message.chat_id, text='Добрый день')\n",
    "\n",
    "# def textMessage(bot, update):\n",
    "    \n",
    "#     input_txt = preprocess_txt(update.message.text)\n",
    "#     vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "#     prediction = lr.predict(vect)\n",
    "    \n",
    "#     if prediction[0] == 1:\n",
    "#         vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "#         ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "#         for item in ft_index_shop_val:\n",
    "#             title, image = index_map_shop[item]\n",
    "#             bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "#         return\n",
    "#     vect_ft = embed_txt(input_txt, {}, 1)\n",
    "#     ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "#     if distances[0] > 0.2:\n",
    "#         print(distances[0])\n",
    "#         bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "#         return\n",
    "#     bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "    \n",
    "def echo(update, context):\n",
    "    \"\"\"Echo the user message.\"\"\"\n",
    "    update.message.reply_text(update.message.text)\n",
    "\n",
    "\n",
    "# обработчики комманд\n",
    "dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "# dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "\n",
    "# \n",
    "dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
    "# text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "# dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
