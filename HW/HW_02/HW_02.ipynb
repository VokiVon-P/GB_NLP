{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема “Создание признакового пространства”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PREP_DATA = '../data/prep_tweets.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим подготовленный датасет твиттов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = pd.read_pickle(PREP_DATA)\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Создайте мешок слов с помощью CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_docs = df_prep['tweet_stemmed'].apply(' '.join)\n",
    "\n",
    "lemmatized_docs = df_prep['tweet_lemmatized'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_bagbag_of_words(vectorizer: object, docs: list) -> object:\n",
    "    \n",
    "    bag_of_words = vectorizer.fit_transform(docs)\n",
    "    \n",
    "    # Отобразим Bag-of-Words модель как DataFrame\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return pd.DataFrame(bag_of_words.toarray(), columns = feature_names).copy()\n",
    "\n",
    "\n",
    "def make_bagbag_of_words_simple(docs: list) -> object:\n",
    "   \n",
    "    count_vectorizer = CountVectorizer(max_df=0.9, max_features = 1000, stop_words='english')\n",
    "    return _make_bagbag_of_words(count_vectorizer, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual  ad  ...  \\\n",
       "0    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "1    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "2    0        0       0        0    0       0      0      0       0   0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmed\n",
    "stemmed_bow = make_bagbag_of_words_simple(stemmed_docs)\n",
    "stemmed_bow.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216726"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_bow.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0     0           0       0        0    0       0      0         0      0   \n",
       "1     0           0       0        0    0       0      0         0      0   \n",
       "2     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "   add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  yummy  \n",
       "0    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "1    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "2    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatized\n",
    "lemmatized_bow = make_bagbag_of_words_simple(lemmatized_docs)\n",
    "lemmatized_bow.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204283"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_bow.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Создайте мешок слов с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bagbag_of_words_tfidf(docs: list) -> object:\n",
    "   \n",
    "    vectorizer = TfidfVectorizer(max_df=0.9, max_features = 1000, stop_words='english')\n",
    "    return _make_bagbag_of_words(vectorizer, docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  activ  actor  actual   ad  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0    0.0     0.0  0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmed\n",
    "stemmed_tfidf = make_bagbag_of_words_tfidf(stemmed_docs)\n",
    "stemmed_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93434.75975058634"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_tfidf.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "1   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "2   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "\n",
       "   add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
       "0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "   yummy  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatized\n",
    "lemmatized_tfidf = make_bagbag_of_words_tfidf(lemmatized_docs)\n",
    "lemmatized_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90534.85481794423"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tfidf.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Натренируем gensim.models.Word2Vec модель на наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, is, dysfunctional, and, is, so,...\n",
       "1    [thanks, for, lyft, credit, can, not, use, cau...\n",
       "2                              [bihday, your, majesty]\n",
       "3    [model, love, you, take, with, you, all, the, ...\n",
       "4               [factsguide, society, now, motivation]\n",
       "Name: tweet_token, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs = df_prep['tweet_token']\n",
    "tokenized_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 164 ms, total: 1min 4s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v = Word2Vec(tokenized_docs, \n",
    "              size=200, \n",
    "              window=5, \n",
    "              min_count=2, \n",
    "              sg = 1, \n",
    "              hs = 0, \n",
    "              negative = 10, \n",
    "              workers= 32, \n",
    "              seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 395 ms, total: 3min 34s\n",
      "Wall time: 55.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9142127, 11726520)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_w2v.train(tokenized_docs, total_examples=tokenized_docs.size, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### потестируем нашу модель Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bihdaydinner: 0.5136\n",
      "[('bihdaydinner', 0.5135906934738159), ('bolognese', 0.5046185255050659), ('spaghetti', 0.4828481674194336)]\n"
     ]
    }
   ],
   "source": [
    "# выведим слово наиболее близкое к 'dinner'\n",
    "result = model_w2v.most_similar(positive=['dinner'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))\n",
    "print(model_w2v.similar_by_word(\"dinner\", topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donald: 0.5253\n",
      "[('donald', 0.5252756476402283), ('dumptrump', 0.5097389221191406), ('impeachment', 0.5059808492660522)]\n"
     ]
    }
   ],
   "source": [
    "# выведим слово наиболее близкое к 'trump'\n",
    "result = model_w2v.most_similar(positive=['trump'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))\n",
    "print(model_w2v.similar_by_word(\"trump\", topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### проверим векторное представление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05453965,  0.43578646, -0.32321855,  0.12719397, -0.3001119 ,\n",
       "        0.34627149,  0.6086251 , -0.28485277, -0.4190308 ,  0.1764305 ,\n",
       "       -1.107064  , -0.13698637,  0.8977579 ,  0.091414  ,  0.32210517,\n",
       "        0.4963126 ,  0.04173763,  0.18582356, -0.16054681, -0.05413775,\n",
       "        0.1107304 , -0.2229657 , -0.5314729 , -0.54554015, -0.10198018,\n",
       "        0.16537338, -0.10190313,  0.03768715,  0.14142726, -0.94008034,\n",
       "       -0.80502886,  0.32982388,  0.01613015, -0.5596173 , -0.35032305,\n",
       "        0.27877343, -0.18316564,  0.40505934,  0.09746268, -0.5181812 ,\n",
       "       -0.23304904, -0.0119802 ,  0.4605858 , -0.10047836,  0.269629  ,\n",
       "        0.14984307,  0.30088153, -0.92244226,  0.13457018,  0.05147889,\n",
       "       -0.13373959,  0.77397066,  0.18748955, -0.16660704,  0.32296014,\n",
       "        0.07679819,  0.04791665,  0.39140555,  0.44024032,  0.19118825,\n",
       "        0.17425205,  0.20088373, -0.3227794 , -0.14851695,  0.3454507 ,\n",
       "        0.0327611 ,  0.4996098 , -0.48416063, -0.1470884 , -0.6019726 ,\n",
       "       -0.08782354, -0.23905282, -0.32340398,  0.06288266, -0.1778894 ,\n",
       "       -0.10777719,  0.1452324 , -0.23162778,  0.01878813,  0.08572058,\n",
       "        0.7503484 , -0.90978956,  0.4548379 , -0.2820796 ,  0.37248167,\n",
       "       -0.42934516, -0.13028921,  0.02151525,  0.19215749, -0.02047692,\n",
       "       -0.04581662,  1.0715051 , -0.18689892,  0.24998857,  0.05510917,\n",
       "        0.06632207,  0.3494492 ,  0.72639763, -0.30832684,  0.18456447,\n",
       "        0.29197502, -0.14848171, -0.4506056 ,  0.09787019,  0.1846205 ,\n",
       "        0.20818397,  0.19221391, -0.17297624, -0.6067541 , -0.49207374,\n",
       "       -0.03610688, -0.28255683, -0.572947  ,  0.21767543, -0.29866764,\n",
       "       -0.3822295 , -0.7153404 , -0.0869453 ,  1.0416945 , -0.37622392,\n",
       "       -0.5565768 ,  0.6902463 , -0.29563412, -0.36036408, -0.01666995,\n",
       "        0.09459595,  0.2615676 ,  0.5837889 ,  0.6832045 ,  0.8628312 ,\n",
       "       -0.7005494 , -0.41143203, -0.08757646, -0.04940572,  0.10084979,\n",
       "       -0.9356519 ,  0.18764295, -0.2192388 , -0.39937517,  0.21014968,\n",
       "       -0.06114884,  0.41902038, -0.16604859,  0.19983439,  0.64513326,\n",
       "        0.1971536 ,  0.48835024, -0.9612286 , -0.32064864, -0.47905338,\n",
       "       -0.5587249 , -0.5589905 , -0.17614692,  0.1248518 ,  0.18834236,\n",
       "        0.16060282,  0.46583697,  0.04731297, -0.41713572,  0.3845915 ,\n",
       "       -0.31175587,  0.45392764, -0.13444518, -0.6032419 ,  0.12729248,\n",
       "        0.1400389 , -0.10486191,  0.53715706, -0.11057629,  0.33781403,\n",
       "        0.8216067 , -0.3352661 ,  0.59935594,  0.12914373, -0.6688908 ,\n",
       "        0.19805779, -0.15144816, -0.11326599,  0.05468505, -0.25033155,\n",
       "       -0.11604742, -0.00490893, -0.03041496, -0.18778239,  0.9597051 ,\n",
       "       -0.5372738 ,  0.15556887, -0.32282433, -0.10672563,  0.15219036,\n",
       "       -0.64212346,  0.0124544 , -0.02162572,  0.08197086, -0.47100103,\n",
       "        0.08011267,  0.895611  ,  0.2944562 ,  0.7565497 , -0.16940737],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['tweet_token'].apply(lambda x: 'disapointed' in x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['food'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимо создать вектор для каждого твита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем вектора для каждого слова и затем усредняем\n",
    "def vectorize_tweet(words: list)-> list or None:\n",
    "    res = None\n",
    "    vec = []\n",
    "    for item in words:\n",
    "        try:\n",
    "            vec.append(model_w2v[item])\n",
    "        except KeyError as err:\n",
    "            pass\n",
    "    if len(vec)>0:\n",
    "        res =  np.average(vec, axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 55.9 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "v2w_tweets = tokenized_docs.apply(vectorize_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159,)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2w_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(49139,)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем наличие твитов состоящие из слов которых нет в нашем словаре\n",
    "print(v2w_tweets.isna().sum())\n",
    "# и удаляем их\n",
    "v2w_tweets.dropna(inplace=True)\n",
    "v2w_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169418</td>\n",
       "      <td>-0.037499</td>\n",
       "      <td>-0.225362</td>\n",
       "      <td>-0.161894</td>\n",
       "      <td>0.025668</td>\n",
       "      <td>-0.006486</td>\n",
       "      <td>0.046818</td>\n",
       "      <td>0.098141</td>\n",
       "      <td>0.153589</td>\n",
       "      <td>0.059346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.275536</td>\n",
       "      <td>-0.120369</td>\n",
       "      <td>0.216542</td>\n",
       "      <td>0.045640</td>\n",
       "      <td>0.113287</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.161259</td>\n",
       "      <td>0.236337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108375</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>-0.215211</td>\n",
       "      <td>0.023472</td>\n",
       "      <td>-0.016073</td>\n",
       "      <td>0.143144</td>\n",
       "      <td>0.136595</td>\n",
       "      <td>0.021114</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>-0.063274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163330</td>\n",
       "      <td>0.141688</td>\n",
       "      <td>-0.098775</td>\n",
       "      <td>0.118237</td>\n",
       "      <td>0.206161</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>0.020088</td>\n",
       "      <td>0.095830</td>\n",
       "      <td>0.154129</td>\n",
       "      <td>0.091501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413979</td>\n",
       "      <td>0.282939</td>\n",
       "      <td>0.185134</td>\n",
       "      <td>-0.234962</td>\n",
       "      <td>-0.180790</td>\n",
       "      <td>-0.032598</td>\n",
       "      <td>0.273386</td>\n",
       "      <td>-0.164979</td>\n",
       "      <td>-0.023248</td>\n",
       "      <td>0.291121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266192</td>\n",
       "      <td>0.324822</td>\n",
       "      <td>0.123923</td>\n",
       "      <td>-0.061326</td>\n",
       "      <td>-0.108655</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-0.268500</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.081810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.169418 -0.037499 -0.225362 -0.161894  0.025668 -0.006486  0.046818   \n",
       "1  0.108375 -0.001371 -0.215211  0.023472 -0.016073  0.143144  0.136595   \n",
       "2  0.413979  0.282939  0.185134 -0.234962 -0.180790 -0.032598  0.273386   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0  0.098141  0.153589  0.059346  ...  0.047995  0.275536 -0.120369  0.216542   \n",
       "1  0.021114  0.072629 -0.063274  ...  0.163330  0.141688 -0.098775  0.118237   \n",
       "2 -0.164979 -0.023248  0.291121  ...  0.266192  0.324822  0.123923 -0.061326   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.045640  0.113287  0.018508 -0.008567  0.161259  0.236337  \n",
       "1  0.206161  0.023188  0.020088  0.095830  0.154129  0.091501  \n",
       "2 -0.108655  0.224779 -0.268500  0.130314  0.466071  0.081810  \n",
       "\n",
       "[3 rows x 200 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df = pd.DataFrame.from_records(v2w_tweets)\n",
    "wordvec_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49139, 200)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49139 entries, 0 to 49138\n",
      "Columns: 200 entries, 0 to 199\n",
      "dtypes: float64(200)\n",
      "memory usage: 75.0 MB\n"
     ]
    }
   ],
   "source": [
    "wordvec_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
