{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW_07\n",
    "Запустить seq2seq, seq2seq с внимаием и трансформер для перевода русских слов + описать наблюдения по качеству\n",
    "\n",
    "\n",
    "# Генерация текстов, encoder-decoder\n",
    "эту модель можно строить на уровне слов и на уровне токенов. Попробуем обучить на уровне токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# кастомные настройки\n",
    "# установка GPU на котором будем работать\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[2], 'GPU')\n",
    "tf.config.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 512\n",
    "num_samples = 10000\n",
    "data_path = '../data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tМарш!\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)\n",
      "Go.\tИди.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898247 (marafon)\n",
      "Go.\tИдите.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #5898250 (marafon)\n",
      "Hi.\tЗдравствуйте.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #402127 (odexed)\n",
      "Hi.\tПривет!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #466968 (katjka)\n",
      "Hi.\tХай.\tCC-BY 2.0 (France) Attribution: tatoe\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read()[:500]\n",
    "    print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping=EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/125 [..............................] - ETA: 0s - loss: 4.4605 - accuracy: 0.0070WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_train_batch_end` time: 0.0331s). Check your callbacks.\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 1.0190 - accuracy: 0.7752 - val_loss: 0.8640 - val_accuracy: 0.7717\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.7432 - accuracy: 0.8125 - val_loss: 0.8470 - val_accuracy: 0.7789\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.6137 - accuracy: 0.8346 - val_loss: 0.6571 - val_accuracy: 0.8180\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.5439 - accuracy: 0.8476 - val_loss: 0.6145 - val_accuracy: 0.8242\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.5107 - accuracy: 0.8544 - val_loss: 0.5843 - val_accuracy: 0.8328\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.4873 - accuracy: 0.8593 - val_loss: 0.5665 - val_accuracy: 0.8358\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.4686 - accuracy: 0.8637 - val_loss: 0.5407 - val_accuracy: 0.8420\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.4511 - accuracy: 0.8683 - val_loss: 0.5315 - val_accuracy: 0.8445\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.4359 - accuracy: 0.8727 - val_loss: 0.5164 - val_accuracy: 0.8495\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.4201 - accuracy: 0.8771 - val_loss: 0.5054 - val_accuracy: 0.8531\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.4062 - accuracy: 0.8810 - val_loss: 0.4937 - val_accuracy: 0.8559\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.4109 - accuracy: 0.8799 - val_loss: 0.4919 - val_accuracy: 0.8576\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.3950 - accuracy: 0.8843 - val_loss: 0.4780 - val_accuracy: 0.8609\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.4390 - accuracy: 0.8797 - val_loss: 0.5335 - val_accuracy: 0.8451\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.4025 - accuracy: 0.8822 - val_loss: 0.4778 - val_accuracy: 0.8616\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.3737 - accuracy: 0.8908 - val_loss: 0.4675 - val_accuracy: 0.8657\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3591 - accuracy: 0.8945 - val_loss: 0.4556 - val_accuracy: 0.8692\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.3464 - accuracy: 0.8983 - val_loss: 0.4492 - val_accuracy: 0.8703\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.3344 - accuracy: 0.9020 - val_loss: 0.4425 - val_accuracy: 0.8735\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.3229 - accuracy: 0.9053 - val_loss: 0.4410 - val_accuracy: 0.8742\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.3110 - accuracy: 0.9084 - val_loss: 0.4339 - val_accuracy: 0.8764\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.3004 - accuracy: 0.9117 - val_loss: 0.4285 - val_accuracy: 0.8782\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2902 - accuracy: 0.9143 - val_loss: 0.4260 - val_accuracy: 0.8795\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 6s 52ms/step - loss: 0.2788 - accuracy: 0.9176 - val_loss: 0.4237 - val_accuracy: 0.8805\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2685 - accuracy: 0.9204 - val_loss: 0.4236 - val_accuracy: 0.8811\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.2576 - accuracy: 0.9235 - val_loss: 0.4253 - val_accuracy: 0.8818\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.2487 - accuracy: 0.9262 - val_loss: 0.4280 - val_accuracy: 0.8814\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.2372 - accuracy: 0.9296 - val_loss: 0.4234 - val_accuracy: 0.8837\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2271 - accuracy: 0.9324 - val_loss: 0.4262 - val_accuracy: 0.8837\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.2175 - accuracy: 0.9351 - val_loss: 0.4255 - val_accuracy: 0.8849\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2084 - accuracy: 0.9377 - val_loss: 0.4298 - val_accuracy: 0.8845\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1991 - accuracy: 0.9401 - val_loss: 0.4322 - val_accuracy: 0.8842\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1905 - accuracy: 0.9424 - val_loss: 0.4363 - val_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1807 - accuracy: 0.9454 - val_loss: 0.4389 - val_accuracy: 0.8852\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.1729 - accuracy: 0.9476 - val_loss: 0.4424 - val_accuracy: 0.8858\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.1662 - accuracy: 0.9493 - val_loss: 0.4486 - val_accuracy: 0.8860\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1582 - accuracy: 0.9517 - val_loss: 0.4525 - val_accuracy: 0.8855\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1505 - accuracy: 0.9540 - val_loss: 0.4626 - val_accuracy: 0.8844\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.1444 - accuracy: 0.9557 - val_loss: 0.4644 - val_accuracy: 0.8853\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1389 - accuracy: 0.9573 - val_loss: 0.4645 - val_accuracy: 0.8866\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1338 - accuracy: 0.9586 - val_loss: 0.4712 - val_accuracy: 0.8863\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1272 - accuracy: 0.9604 - val_loss: 0.4776 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1218 - accuracy: 0.9621 - val_loss: 0.4819 - val_accuracy: 0.8869\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1180 - accuracy: 0.9630 - val_loss: 0.4866 - val_accuracy: 0.8859\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.1132 - accuracy: 0.9644 - val_loss: 0.4962 - val_accuracy: 0.8850\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1095 - accuracy: 0.9652 - val_loss: 0.5004 - val_accuracy: 0.8858\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1051 - accuracy: 0.9666 - val_loss: 0.5026 - val_accuracy: 0.8863\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 0.5075 - val_accuracy: 0.8854\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0988 - accuracy: 0.9681 - val_loss: 0.5096 - val_accuracy: 0.8858\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0953 - accuracy: 0.9690 - val_loss: 0.5132 - val_accuracy: 0.8862\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.0917 - accuracy: 0.9702 - val_loss: 0.5222 - val_accuracy: 0.8869\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0967 - accuracy: 0.9684 - val_loss: 0.5179 - val_accuracy: 0.8865\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.0885 - accuracy: 0.9708 - val_loss: 0.5235 - val_accuracy: 0.8872\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0842 - accuracy: 0.9721 - val_loss: 0.5221 - val_accuracy: 0.8878\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0807 - accuracy: 0.9730 - val_loss: 0.5303 - val_accuracy: 0.8876\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0787 - accuracy: 0.9736 - val_loss: 0.5356 - val_accuracy: 0.8867\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0768 - accuracy: 0.9741 - val_loss: 0.5394 - val_accuracy: 0.8866\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0746 - accuracy: 0.9748 - val_loss: 0.5443 - val_accuracy: 0.8870\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.0725 - accuracy: 0.9753 - val_loss: 0.5473 - val_accuracy: 0.8872\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.0708 - accuracy: 0.9758 - val_loss: 0.5544 - val_accuracy: 0.8864\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0683 - accuracy: 0.9765 - val_loss: 0.5517 - val_accuracy: 0.8872\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0664 - accuracy: 0.9771 - val_loss: 0.5650 - val_accuracy: 0.8864\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0654 - accuracy: 0.9771 - val_loss: 0.5721 - val_accuracy: 0.8849\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 6s 52ms/step - loss: 0.0656 - accuracy: 0.9771 - val_loss: 0.5646 - val_accuracy: 0.8872\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0623 - accuracy: 0.9782 - val_loss: 0.5667 - val_accuracy: 0.8874\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0603 - accuracy: 0.9786 - val_loss: 0.5697 - val_accuracy: 0.8874\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.5775 - val_accuracy: 0.8872\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0579 - accuracy: 0.9792 - val_loss: 0.5765 - val_accuracy: 0.8876\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.5813 - val_accuracy: 0.8871\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0545 - accuracy: 0.9801 - val_loss: 0.5871 - val_accuracy: 0.8879\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0534 - accuracy: 0.9805 - val_loss: 0.5806 - val_accuracy: 0.8876\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.0524 - accuracy: 0.9808 - val_loss: 0.5970 - val_accuracy: 0.8873\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0548 - accuracy: 0.9800 - val_loss: 0.5916 - val_accuracy: 0.8877\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0521 - accuracy: 0.9806 - val_loss: 0.5886 - val_accuracy: 0.8872\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0492 - accuracy: 0.9818 - val_loss: 0.5912 - val_accuracy: 0.8876\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0476 - accuracy: 0.9820 - val_loss: 0.5998 - val_accuracy: 0.8869\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.5957 - val_accuracy: 0.8879\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0462 - accuracy: 0.9826 - val_loss: 0.6015 - val_accuracy: 0.8877\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0448 - accuracy: 0.9829 - val_loss: 0.6045 - val_accuracy: 0.8870\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0444 - accuracy: 0.9829 - val_loss: 0.6081 - val_accuracy: 0.8870\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0433 - accuracy: 0.9834 - val_loss: 0.6123 - val_accuracy: 0.8863\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0430 - accuracy: 0.9833 - val_loss: 0.6137 - val_accuracy: 0.8874\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0426 - accuracy: 0.9835 - val_loss: 0.6127 - val_accuracy: 0.8864\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0423 - accuracy: 0.9836 - val_loss: 0.6123 - val_accuracy: 0.8872\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0410 - accuracy: 0.9838 - val_loss: 0.6158 - val_accuracy: 0.8871\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 6s 52ms/step - loss: 0.0405 - accuracy: 0.9840 - val_loss: 0.6176 - val_accuracy: 0.8872\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0399 - accuracy: 0.9841 - val_loss: 0.6211 - val_accuracy: 0.8875\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0391 - accuracy: 0.9842 - val_loss: 0.6297 - val_accuracy: 0.8865\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0386 - accuracy: 0.9845 - val_loss: 0.6237 - val_accuracy: 0.8874\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0384 - accuracy: 0.9846 - val_loss: 0.6278 - val_accuracy: 0.8867\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0377 - accuracy: 0.9846 - val_loss: 0.6301 - val_accuracy: 0.8874\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0373 - accuracy: 0.9849 - val_loss: 0.6336 - val_accuracy: 0.8871\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0370 - accuracy: 0.9850 - val_loss: 0.6357 - val_accuracy: 0.8864\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 0.6423 - val_accuracy: 0.8852\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.6141 - val_accuracy: 0.8843\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.6198 - val_accuracy: 0.8873\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0370 - accuracy: 0.9849 - val_loss: 0.6217 - val_accuracy: 0.8890\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.0340 - accuracy: 0.9856 - val_loss: 0.6224 - val_accuracy: 0.8882\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0327 - accuracy: 0.9858 - val_loss: 0.6261 - val_accuracy: 0.8888\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0327 - accuracy: 0.9858 - val_loss: 0.6299 - val_accuracy: 0.8881\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Кто?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Здорово!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Пожар!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прыгай!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Остановитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Ждите!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Сделай это.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Продолжай.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Здравствуйте.\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Поспешите.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я побежала.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Понятно.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Понятно.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Понятно.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я пытаюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я пытаюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я пытаюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграла!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграла!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграла!\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я выиграла!\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: О нет!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Расслабьтесь.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Стреляй!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Улыбнитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: В атаку!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: За Ваше здоровье!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Съешь это.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Доедай.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Застынь!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Вставай.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Вставай.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Вставай.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Теперь иди.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Понял!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2,\n",
    "          # callbacks=[early_stopping]\n",
    "         )\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "# на 10000 - ругается и обзывается :) - в прямом смысле - на русском!\n",
    "word_num_samples = 20000\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    \"\"\" добавим русский язык в препроцесинг \"\"\"\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(word_num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1024 #batch_size\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2.7065\n",
      "Epoch 2 Loss 2.1173\n",
      "Epoch 3 Loss 1.9632\n",
      "Epoch 4 Loss 1.8564\n",
      "Epoch 5 Loss 1.7799\n",
      "Epoch 6 Loss 1.7220\n",
      "Epoch 7 Loss 1.6880\n",
      "Epoch 8 Loss 1.6523\n",
      "Epoch 9 Loss 1.6127\n",
      "Epoch 10 Loss 1.5708\n",
      "Epoch 11 Loss 1.5331\n",
      "Epoch 12 Loss 1.4799\n",
      "Epoch 13 Loss 1.4147\n",
      "Epoch 14 Loss 1.3498\n",
      "Epoch 15 Loss 1.2928\n",
      "Epoch 16 Loss 1.2386\n",
      "Epoch 17 Loss 1.1860\n",
      "Epoch 18 Loss 1.1461\n",
      "Epoch 19 Loss 1.1117\n",
      "Epoch 20 Loss 1.0751\n",
      "Epoch 21 Loss 1.0398\n",
      "Epoch 22 Loss 1.0074\n",
      "Epoch 23 Loss 0.9758\n",
      "Epoch 24 Loss 0.9553\n",
      "Epoch 25 Loss 0.9186\n",
      "Epoch 26 Loss 0.8888\n",
      "Epoch 27 Loss 0.8582\n",
      "Epoch 28 Loss 0.8286\n",
      "Epoch 29 Loss 0.7986\n",
      "Epoch 30 Loss 0.7647\n",
      "Epoch 31 Loss 0.7298\n",
      "Epoch 32 Loss 0.6959\n",
      "Epoch 33 Loss 0.6610\n",
      "Epoch 34 Loss 0.6266\n",
      "Epoch 35 Loss 0.5943\n",
      "Epoch 36 Loss 0.5636\n",
      "Epoch 37 Loss 0.5371\n",
      "Epoch 38 Loss 0.5081\n",
      "Epoch 39 Loss 0.4780\n",
      "Epoch 40 Loss 0.4527\n",
      "Epoch 41 Loss 0.4270\n",
      "Epoch 42 Loss 0.4045\n",
      "Epoch 43 Loss 0.3803\n",
      "Epoch 44 Loss 0.3591\n",
      "Epoch 45 Loss 0.3403\n",
      "Epoch 46 Loss 0.3234\n",
      "Epoch 47 Loss 0.3043\n",
      "Epoch 48 Loss 0.2920\n",
      "Epoch 49 Loss 0.2763\n",
      "Epoch 50 Loss 0.2614\n",
      "Epoch 51 Loss 0.2497\n",
      "Epoch 52 Loss 0.2410\n",
      "Epoch 53 Loss 0.2329\n",
      "Epoch 54 Loss 0.2204\n",
      "Epoch 55 Loss 0.2120\n",
      "Epoch 56 Loss 0.2037\n",
      "Epoch 57 Loss 0.1953\n",
      "Epoch 58 Loss 0.1892\n",
      "Epoch 59 Loss 0.1841\n",
      "Epoch 60 Loss 0.1780\n",
      "Epoch 61 Loss 0.1739\n",
      "Epoch 62 Loss 0.1703\n",
      "Epoch 63 Loss 0.1662\n",
      "Epoch 64 Loss 0.1624\n",
      "Epoch 65 Loss 0.1595\n",
      "Epoch 66 Loss 0.1551\n",
      "Epoch 67 Loss 0.1517\n",
      "Epoch 68 Loss 0.1494\n",
      "Epoch 69 Loss 0.1460\n",
      "Epoch 70 Loss 0.1436\n",
      "Epoch 71 Loss 0.1397\n",
      "Epoch 72 Loss 0.1381\n",
      "Epoch 73 Loss 0.1349\n",
      "Epoch 74 Loss 0.1330\n",
      "Epoch 75 Loss 0.1318\n",
      "Epoch 76 Loss 0.1302\n",
      "Epoch 77 Loss 0.1294\n",
      "Epoch 78 Loss 0.1282\n",
      "Epoch 79 Loss 0.1256\n",
      "Epoch 80 Loss 0.1248\n",
      "Epoch 81 Loss 0.1237\n",
      "Epoch 82 Loss 0.1212\n",
      "Epoch 83 Loss 0.1211\n",
      "Epoch 84 Loss 0.1193\n",
      "Epoch 85 Loss 0.1191\n",
      "Epoch 86 Loss 0.1184\n",
      "Epoch 87 Loss 0.1171\n",
      "Epoch 88 Loss 0.1160\n",
      "Epoch 89 Loss 0.1151\n",
      "Epoch 90 Loss 0.1165\n",
      "Epoch 91 Loss 0.1167\n",
      "Epoch 92 Loss 0.1161\n",
      "Epoch 93 Loss 0.1151\n",
      "Epoch 94 Loss 0.1141\n",
      "Epoch 95 Loss 0.1124\n",
      "Epoch 96 Loss 0.1110\n",
      "Epoch 97 Loss 0.1100\n",
      "Epoch 98 Loss 0.1087\n",
      "Epoch 99 Loss 0.1076\n",
      "Epoch 100 Loss 0.1076\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = epochs\n",
    "# EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "#     ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "#     ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Input: <start> good morning <end>\n",
      "Predicted translation: с добрым утром <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/develop/_DS_/_env_/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> good morning my friend <end>\n",
      "Predicted translation: уроки в нос чешется <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> how was your day today <end>\n",
      "Predicted translation: она была храброй <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHfCAYAAADA/WmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd7wldX3/8debZRdwVyyICir2glgQVwSxoCSx19gpAlFiiaKoMfyMJSHG2DEaosSC2BtKjIoVRAhqwIaCUnQlCCgYpS67lM/vj5nVw2HvVnbnzv2+no/HfdxzZubM+dx53N3zvt/5llQVkiRJascmQxcgSZKkjcsAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAPgHJDkrkm+meTeQ9ciSZJmPwPg3PAcYHdg/4HrkCRJI5CqGroGrYckAZYAXwMeD2xbVdcMWpQkSZrVbAEcv92BGwMvAa4GHjNoNZIkadYzAI7fc4DPVNUVwCf655IkSTPyFvCIJVkInA88tqq+nWRH4CRgm6r6w7DVSZKk2coWwHH7S+Ciqvo2QFX9EDgTeOagVUmSNMclWZhknyQ3GbqWdWEAHLe9gY9MbfsIsO/GL0WSpKY8Hfgg3Wfx6HgLeKSS3A74JbB9VZ05sf22dKOC71lVZwxUniRJc1qSY4FbAVdU1eKh61lbBkBJkqS1kOQOwBnAzsB3gJ2q6rQha1pb3gIesSTb9fMArnTfxq5HkqRG7A18u+97/yVGOAOHAXDcfglsPb0xyVb9PkmSdMPbB/hw//ijwJ4zNcjMVgbAcQuwsnv4i4ArN3ItkiTNeUkeBGwDfKbf9AXgRsCfDVbUOth06AK09pL8a/+wgDcmuWJi9zy6Pgk/3OiFSZI09z0HOLqqLgOoquVJPkU3A8fXhixsbRgAx+ne/fcA2wPLJ/YtB74PvHVjFyVJmt2S7Nj3W9M6SLIZ3fQvz5ra9RHgK0kWrQiGs52jgEeq72vwKWD/qrp06HokSbNfkmuBHwDvAz5WVRcPXNKoJLkF8BjgI1V17dS+vYCvV9UFgxS3lgyAI5VkHl0/v/uObei5JGkYSe4K7E83ivVmwOeA91fVsYMWpo3OQSAjVVXXAL8CFgxdiyRpHKrqzKo6GNiO7lbm5sAxSc5O8up+MQE1wBbAEUvyHLp+CHtV1UVD1yNJGpckmwMvAN5I16BwNXAU8PKq+vWQtc0mSX7JymfduJ6qutMGLucGYQAcsSSnAncE5gPnApdP7q+q+wxRlyRpdkuyM92t4GcAl9CtafsBuulN/hG4eVU9YLgKZ5ckL594ugg4CPgecFK/bVe6GTjeVlX/uJHLWycGwBFL8rpV7a+qf9hYtUiSZr8kBwH7AXcDvkg3GOSYyQENK9aUrypnClmJJEcAZ1TVP09tPxjYoar2GqSwtWQAlCSpEUnOBN4PfLCqfjPDMQuAZ1XVhzZqcSOR5BK6tX/Pmtp+F+D7VbXlMJWtHdO9JG1ESeYDbwD+rap+NXQ9aktV3XUNjlkOGP5mdjmwO3DW1PbdgSumD56tDIAj1v+V9mq6gSDb0fUF/KOqmjdEXZJmVlVXJXkhcNjQtahdSbal+9y4zkwSVXX8MBWNyjuAf0uyGPhOv20XuhVCXj9UUWvLADhuh9B14H0j3S/kK4E7AM8EXjNcWZJW4yvAI+g63UsbTR/8Pg48hG5U6/Sa8jYcrEZVvTnJEuBAuql0AE4HnlNVnxqssLVkH8AR64elv6CqjklyKbBjVZ2d5AXAHlX11IFLlLQSfQvga4FPAKdw/RH8Rw1Rl+a+fs3arYAXAf8DPAq4Fd3I35dV1WjWstX6MQCOWJIrgHtU1TlJzgceV1WnJLkj8KOxdEQdSpJtq+q8oetQe/rluGZSdt/QhpLkN8Bjq+rkfjDD4qo6I8ljgddU1S4DlzgqSW7K1KIaVfV/A5WzVlwJZNzOAbbtH58FPLJ/vCuwdJCKxuXcJGckOTzJs/tbI1oDSR6W5IETz/dNckKS9yZZNGRtY1BVm6ziy/CnDWkLYMXCAf8H3LJ/fBrg3LFrIMntk3w5yVLgd8CF/ddF/fdRMACO2+eAPfrH7wT+ob8tfATd3E5atbsCb6L7D/FfuG4gfNawpc16hwK3Bkhyd+C9wI/p/vh4y4B1qQFJdhy6hhH7GXCP/vEPgecnuT3dLWFX/lgzH6S7bf5XdJ/Bj+i/Ht5/HwVvAc8hfYvMbnQTVP7X0PWMTZJ7AH8L7AXMsyVmZn2f0/tW1S+S/D/gQVX1uP538LNV5Xqiq9BPxjujqnr7xqpljPpb6D+g+0P3Y1V18cAljUaSPYH5VXVEkp2AY+j6BC6jG8Tw6UELHIEklwG7VNVPhq5lfRgARyzJQ4H/rqqrp7ZvSveB7HD+VUiyCbCY7q+23enC8++A44DjnAR1Zkkupus7dGaSbwCfq6p39y0JP6uqLQYucVbrW+onzadbgmsp8NuxrCU6lCR3pVvGbG/gZnR3Q95fVccOWtgIJbkRXYvgOa4pv2b6ZVj3rapThq5lfRgARyzJNcA2VfXbqe1b0X2I2IK1Cn0H6CuB/6ILfd9yYt41k+TrwHnA1+hWFdi+H4H+MLoVBgwwaynJrehuLf1HVX1u6HrGoP8j7tF0S5s9nm5N9A8AH6qqc4esTXNXkkcAfwe8cHo1kDExAI5YfxvkVlV14dT2uwEnOwp41ZKcQNcCeDZwbP91XFX9btDCRiDJvYCPAbcH3r5i3ekk7wZuVlV7DlnfWCW5H/CpNVmtQX+SZHPgBXRzoi4ArgaOAl5eVc33a0uyxvNNVtX+G7KWuaDvArMZ3ZyJy+h+3/5oLJ+9TgQ9Qkn+s39YwEeSLJvYPQ+4F/DfG72wkamqByfZAngQ3S3glwIfTnIWcGxVHThkfbNZ3/dlZSMGXwFcs5HLmUs2oetcrjWQZGe6W8HPAC6hG8z1Abrb6f8IfB54wGAFzh5bTz1/KHAtcGr//F50v3t2G1ozfzN0ATcEWwBHKMkH+4fPAT7Fdad8WQ4sobuNZH+ONdTffnsE8Fi6md0dBKINJslTpjfRhZYXAb+oqsdu/KrGox9Esx9wN+CLdINBjqmqayeOuS2wpKps6JiQ5GDgfsB+VXV5v20hXVeOU6vqDUPWp43HADhiSV4HvHXFP2KtnSRPp2v5ezjdB8kFdH8BH0d3K/jngxU3Akn240/rUE+vJ2ofwFVYyUTQRTd/2Dfpbluev/GrGo8kZ9IFlg9W1W9mOGYB8CwHc11Xv2jAHlV12tT2HYBvVNWth6lsXPpGg72BO9NNoH1Rkt2A86pqepDXrORfRuN2yOSTJLcGHgecVlXeAl69Q4Fv9d8NfGshySuBg+nm/3socBhwl/7xWwcsbRSqyjlY18Oa9JGsquWA4e/6FtEtIHDa1PZtgBtt/HLGJ8n9gW8AvwR2oJv79CLgz+kaE549XHVrzhbAEUvyZbrbHu/sV1/4GbCQ7h/4X1XVkYMWqDkryRnA/6uqz0zNCfgaYLuqet7AJaoB/eo9K2uBti/bDJIcQTd58SuB7/Sbd6GbFP/Yqtp3mMrGI8mxwPFV9bqp//92BT5RVbcfuMQ1YgvguC2mm7gY4Cl0naDvCOxJ1xnfALgaSTaju173pLsNdxrdxLLLVvlC3Rb4Xv94KbBi1NvH++0GwNXo1159Fdf93XtTVX1p0MJGoA9+HwceQnft0n9fwf67M3sB8Da6FaPm99uuprul/oqBahqb+9OtAjLtfEY0iMvbEOO2CPhD//gv6CbjvYquH9GdB6tqJJLcEzgTeDvwQLq/gt8BnJFk+yFrG4ELgFv0j39FtwQcdLeBva2wGkmeSzd58dl0IfDv6G4nfS6J03Cs3qF0oeWewBV0QfBpwOnAowasa9arqqVV9UK61T/u13/dvKpeWFVXDFvdaCylm4B82j2A365k+6xkC+C4nQPsluQLwCPp/gMEuDndf4patXfSLSe1d1VdApBkS+AjdB8wjxywttnuWOAJwPfpWg7e0Q+q2YluZLpW7VXAQVX17olt709yCl0YXON52xr1MOCxVfWzJAVcWFUn9lNiHUI3QblW7Rq6qWAKp25aW0cDr0uy4jO3ktyB7jb6Z4cqam3ZB3DEkvw18G7gMrpWmJ2q6tokLwGeVFWjWZR6CEmuAB5QVT+d2n5v4DtVtXCYyma/JKGbKufq/vkz6NehBt7bt0RrBn1Q2WF6FYEkdwF+WlWbDVPZOPSr+NynqpYkWQLsVVUnJLkj3fVzMMMM+qVC30g3l90Cutvny4B3Aa/23+7q9Q0FX6KbC3Uh3R2RW9HNv/vosczMYQvgiFXVe5OcTNcJ+msTc2CdDbxmuMpG40rgpivZfpN+n2b2FeDYJN8CvldVnwQ+OXBNY3IO3YjB6WWk/oLujzmt2s/obrctAX4IPD/J/9LNo9j8yh+r8Wa66ZueD5zQb3sIXSjcBPsBrlZ/x+jB/ZJwO9Fdt+9X1deHrWzt2AI4UkluQvcX8LdXsm83uqlgfr/xKxuPJB+iWyXgefxpNNyudFObfK+q9huqttkuyT/R3YZ7AHAVcBL9/Il01+7qGV+sFa3376KbpmTFlE270c0r9uKqOnyo2sYgyZ7A/Ko6IslOwDF0fVKXAftU1acHLXAWS3IBsP/0YKN+UNL7qmqbYSobh7n02WsAHKkkN6YbcfTIqjpxYvt96UZh3saVQFYtyU3pPoAfz5/6wMyj69+xX1X9YabXqjO1lN7udINprhzLWphDSvJk4OXAigFHpwNvqaqjh6tqnJLciK5F8Bz/31u1JEuBHafnPU1yD+AHVbXFMJWNw1z67PUW8EhV1aVJjgb2AU6c2LU38JWx/AIOqQ94T+z7Xf3xQ3i6X5ZWaUu6lpdb0vWBuRo4ZdCKRiDJ5+mWL3vo5PJlmlmSNRoYk4SqciT1zH4EvITudvmkA+lup2sV5tJnry2AI5bkkXRzYd26qpYn2QQ4F/ibqjpq2OrGoR+8sAddgLnOtEhV9YRBihqBJIfRtfjdHvgu3Yoqx9ENnnEOxdVI8lHgScDFdPOxfcA/PFatn+1g0kPpRrGe2j+/F92/4eP9tzuzJA+lG8Dwa647EfS2dAMYTpjpterMlc9eA+CI9b90/0vXZ+ioJH9O90u5jSO5Vi/JW4CX0k1pch5T89fZB3Bm/Vq2F9KNQv8ycEr5n8la6UcS7gnsRzep+wl0rYKfrqqlQ9Y22yU5mG7+uv1WjLhMspBuSqJTq+oNQ9Y3myXZjq6l/kV0t82h635wGLBpVZ0zVG1jMVc+ew2AI5fkTcDdq+pJSY4ELq2q6aZ9rUSS3wAvqqrPDF3L2CS5M3/q9/cw4MZ0AeZYunWVvz9YcSOUZAfguXQjM5fRjag+tKpOH7SwWSrJ+cAeVXXa1PYdgG9U1a2HqWz2S3INXVD57dT2rYDfVpWrqKyBufDZ60og43ck8Kj+r7on4+Lna2MT7POyTqrq7Kp6f1XtXVXb0Y2evhD4F+B/hq1uXPplzZ4IPI6uZeazwO2AHydxSo6VW0R3y3LaNoBzAK7a9LJ5KyzC6a/Wxug/e20BnAP6uQCXAreoKpcwW0NJ3gBcVVWvH7qWselvgSwGHk7XCrgbsDndAJDjqurg4aqb/ZLMpwt9+9PNB/gD4D+Aj1fVZf0xTwCOrKqVzVXZtCRH0PXdfSXX7cf2JuDYqtp3mMpmryT/2j98EfBBrrta1DxgZ2B5Ve22sWsbq7F/9joKeG44km7pslcPXchsN/GfIHQtgHv2/Td+TDef3R9V1Us2Zm0j8wdgM7ql4I6j+/07YSwz4M8C59O1xHwM+Luq+vFKjjkeGMV8YgN4AfA2ugE08/ttV9P1AbTVdOXu3X8P3awHyyf2Laf7t/zWjV3UyI36s9cWwDkgyc2BF9MtwXXB0PXMZkmOXcNDy6X0ZtaPgjPwraMke9MN9vCW23roB37cuX96tr+Pq5fkg8CBK9Y/17ob+2evAVCSJKkxDgKRJElqjAFQkiSpMQbAOSTJAUPXMGZev3XntVs/Xr/14/VbP16/dTfma2cAnFtG+4s4S3j91p3Xbv14/daP12/9eP3W3WivnQFQkiSpMY4CXgsLslltzsKhy5jRVSxjPpsNXcZoef3Wnddu/Xj91s+svn7J0BWs1lV1JfOz+dBlrNTd7j27Z/a58HfXsPVWs3f1vFN+vOyiqtp6ZfucCHotbM5CHpg9hi5DkjQS2WyWBtOROOYr3x26hFGbt81Zv5ppn7eAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxowuACbZLMmhSX6T5Mok30ny4H7f7kkqyS2mXnNZkn0nnv9Lkp8nWZpkSZI3J9l8I/8okiRJgxhdAATeDDwD2B+4H3AqcEySbdbiHJf3r98eeCHwTODVN3CdkiRJs9KoAmCShcALgFdV1Rer6nTg+cBvgBet6Xmq6pCqOrGqllTVl4B/Bp41w3sekOTkJCdfxbIb4KeQJEka1qZDF7CW7gzMB05csaGqrklyEnBP4Ov95iVJJl+3cPJJkqcCLwXuAiwC5vVf11NVhwOHA2yZm9cN8lNIkiQNaFQtgKsxGc4eDuw48XXFih1JdgE+AXwFeDzdbeS/pwuWkiRJc97YWgDPBpYDu/WPSTIP2BX42MRxv6yqi1Y8STIZDncDfl1Vh0zsv/2GLFqSJGk2GVUArKrLk/w78KYkFwG/BF4G3Ao4DLj7GpzmDOA2SfYETgIeyQz9/yRJkuaiUQXA3qv67x8Ebgr8AHhUVZ2fZLUBsKq+kOQtwKHAFsBXgdfSBUhJkqQ5L1WOa1hTW+bm9cDsMXQZkqSRyGabDV3CqB3zy+8OXcKozdvmrFOqavHK9s2lQSCSJElaAwZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWrMpkMXMCoJmb9g6CrUoE0WbjF0CaNWt91m6BJG7fK7bDl0CaN17aYZuoRR2/ngnYYuYeRePuMeWwAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWrMrA2ASeYPXYMkSdJcNGsCYJI7Jfn3JKcl+R2wNMndh65LkiRprpkVATDJ9sApwKbA/sADgTtX1c8HLUySJGkO2nToAnrvBg6rqlcPXYgkSdJcN3gLYJKFwMOBBUnOTHJlklOTPLHff4cklWTxDK9fkuQVU9uO6F8z+fXuif0HJflxksuT/DrJ+5LcdEP+nJIkSbPF4AEQ2AoI8NfA64D7AJ8Djkqy4zqeM8DXgW36r5Om9l8LvBTYAXg2sDPwrpWeKDkgyclJTr6qrlzHciRJkmaP2RAAV9Tw1qr6WFWdUVWvBb4NvGIVr1uV+cBlVXVBVV0ALJ/cWVWHVtU3q2pJVX0L+Fvg6Umudz2q6vCqWlxVi+dn83UsR5IkafaYDQFwhROnnp8A3HPi+fFJLktybpLPJrnjKs51E+DymXYmeUSSr/XnuhQ4ClgA3Hpdi5ckSRqL2RAAf7+KfTXx+NnAjsDTgG2BI1fxum2B81a2I8ntgS8Cp/fnuj/dyGPoQqAkSdKcNngArKqLgQuA3aZ2PRg4beL5uVV1VlWdBLwHuN/KzpfkxsD2wA9meMvFdEHvZVV1UlWdQRcYJUmSmjBbpoF5B/D3Sc6kmw9wL+AhwE4TxyxIsjmwNfAM4CfTJ+nnE3wLcDFdK9/KnEkXfF+a5ChgF7oBIZIkSU0YvAWw9zbgncBb6YLdk4CnVNWPJo45EVgKnArMA56zkvMcQvcz7VFVl6zsjarqx8CBwEF0LYzPZd0Hm0iSJI1Oqmr1RwmALTfZqnaZ/6ihy1CDNlm4xdAljFrddpuhSxi1y++y5dAljNa1m2boEkZt+cLZ0k41Tqcc8fJTqmql8yh7ZSVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMZsOXcCYXHuTG3H5I+43dBmjtejMi4cuYbTqrCVDlzBqOf+3Q5cwast2utnQJYzWonOXD13CqG153JKhS5izbAGUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxszoAJpk/dA2SJElzzawKgEl2T/KZJGcnuQT4ZZJsgPc5pX+veUk+nuRxN/R7SJIkzVazJgAm2RP4AnAy8GRgJ+D+VVUb4O3eAnwZuBLYDvjaBngPSZKkWWnToQsASLIIeDfwl1X11Q39flX1iSRHAzepqgs29PtJkiTNJqttAUyydZLzk7xuYtt9klyZ5GlJXp/kJ0mem+ScJEuTfD7JLSaOf0CSrya5KMklSU5IsuvE2zwEWAY8Mcl5Sa5I8vUkO0ycY98klyV5fJIz+vc/Nsmdpur96yRnJVnef3/e1P5K8tSqWlpVFyT5q37bu9fh+kmSJI3OagNgVV0I7Au8OsmuSbYAPg58vKo+3R92B2Av4InAnwF3BT4wcZobAx+mC3o7Az8EvpRkq37/1sCtgD2AZwIPBK4Ajunfb4XNgNcB+wG7AvOAo1b0E0zyZLqWxEOBewHvBA5L8viV/WxJFgKHAJet7jpIkiTNFWt0C7iqvpLkMOCjwLfogtiLJw7ZAtinqs6BrhUO+HaSu1bVmVX1zcnzJXkx8JfAo4GP8KcgekBVHd8fszdwDrAn8L6Jeg+sqhMnjvkFXXD8OvAK4MNVtaI174wk9wdeRde/cNorgdNWdR2SHAAcALBgi5vOeI0kSZLGYm0GgbwKWA7sA+xZVZOtZr9eEf563wWuBbYHSHLLJO/tb91eDFwK3JJuAMYK1wInrXhSVRcDpwL3nDrmexPH/Ao4b+KY7YETp+o+Yeoc9DVtCxwEvHxVP3RVHV5Vi6tq8fzNFq3qUEmSpFFYmwB4B+B2QAF3WvWh1/Mh4AHAy4AHATsC5wIL+v2/X8Vrp0cBr8uo4JW95hDgM1X1o3U4nyRJ0mitUQDsJ2T+GPCfdLdZD0sy2Xp3myS3m3i+c3/u0/vnDwbeVVVfrKqf0rUAbjNx/M/64/84MCTJlsC96W7RTta788Qx2wHbTrzP6cBuU+U/eOocAPcBngb8/cw/tSRJ0ty0ptPAHEI3UGMP4GLgUcCRSR7R718KfCjJQXT9Ad8DfLGqzuz3nwHsleS7wELgzXS3kwGoqp8n+TLw3r7P3R+ANwCX0AXPFa4GDk1yYP+e7wB+Stf/D7r5/T6d5BTgq32dewJPmfp5DgLeVlXnreHPL0mSNGesyTQwD6PrJ7dPVf2hn5h5X7p+da/qD1sCfIJuoMU36QZm7Ddxmv2BRcAp/XEf6F8zaR/g+/05vksXJB9ZVUsnjllGFwyP7I/ZBHjKismiq+rzdINTXkbX6ncg8MKqmh4AcildCJUkSWrOalsAq+pbwPypbRfQDeIgyev7bYcDh89wjh/RTe0y6cNTx1xE11q3unqOBo5exf730LVAzrT/ekvLVdXuq3tfSZKkuWLWLAUnSZKkjcMAKEmS1Jj1DoBV9fqqutcNUcxq3ueIqnIiPkmSpPVkC6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYwyAkiRJjTEASpIkNcYAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYwyAkiRJjTEASpIkNcYAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYzYduoAxmXfJUhZ95dShyxituuaaoUsYrU0WLRy6hFFb8sJ7DF3CqG13zKVDlzBaV914wdAljFptu/XQJYzbhTPvsgVQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSeONRhAAAAdvSURBVGqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaMycDYJJXJFkydB2SJEmz0ZwMgJIkSZrZRg+ASbZMctON/J5bJ9l8Y76nJEnSbLVRAmCSeUkemeRjwAXAffvtN0lyeJLfJrk0ybeSLJ543b5JLkuyR5KfJLk8ybFJ7jh1/r9NckF/7JHAoqkSHgNc0L/Xbhv4x5UkSZrVNmgATLJDkjcD/wt8ErgceBRwfJIAXwRuAzwOuB9wPPDNJNtMnGYz4GBgf2BX4KbAeybe4+nAPwGvA3YCfg4cNFXKR4FnAzcGvpbkrCSvnQ6SkiRJLbjBA2CSrZK8JMkpwA+AewAHAreuqudV1fFVVcDDgR2Bp1bV96rqrKp6DfALYO+JU24KvKg/5sfAW4Hd+wAJ8FLgQ1X13qo6o6reAHxvsqaqurqqvlRVzwJuDfxz//5nJjkuyf5JplsNV/w8ByQ5OcnJy+vKG+YiSZIkDWhDtAC+GHgncCVwt6p6QlV9uup66en+wI2AC/tbt5cluQy4F3DnieOWVdXPJ56fBywAbtY/3x44aerc08//qKouqaoPVNXDgQcAtwLeDzx1huMPr6rFVbV4gd0IJUnSHLDpBjjn4cBVwD7AT5J8Dvgw8I2qumbiuE2A3wAPWck5Lpl4fPXUvpp4/VpLshndLee96PoG/pSuFfHodTmfJEnS2NzgLYBVdV5VvaGq7g78GXAZ8Ang3CRvS7Jjf+j36Vrfru1v/05+/XYt3vJ0YJepbdd5ns6Dk7yXbhDKu4CzgPtX1U5V9c6q+v3a/7SSJEnjs0EHgVTVd6rqBcA2dLeG7wb8T5KHAF8HTgSOTvLoJHdMsmuSf+j3r6l3As9J8rwkd01yMPDAqWP2Ar4KbAk8C7hdVb2yqn6ynj+iJEnS6GyIW8DXU1XLgM8An0lyS+Caqqokj6EbwfsfwC3pbgmfCBy5Fuf+ZJI7AW+g61P4n8DbgX0nDvsG3SCUS65/BkmSpLakG5CrNXGTebeoXbZ47NBljFZdc83qD9JKbbJo4dAljNqSF95j6BJGbbtjLh26hNG66sYLhi5h1BZcdPnQJYzaV3/0T6dU1eKV7XMpOEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMZsOXcCY1LXXcu0VVwxdhhp0zbJlQ5cwarc75L+HLmHUaugCRswP2fVz7dAFzGG2AEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYwyAkiRJjTEASpIkNcYAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYwyAkiRJjTEASpIkNcYAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjDICSJEmNMQBKkiQ1xgAoSZLUGAOgJElSYwyAkiRJjTEASpIkNcYAKEmS1BgDoCRJUmMMgJIkSY0xAEqSJDXGAChJktQYA6AkSVJjNh26gNkuyQHAAQCbc6OBq5EkSVp/tgCuRlUdXlWLq2rxfDYbuhxJkqT1ZgCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTEGQEmSpMYYACVJkhpjAJQkSWqMAVCSJKkxBkBJkqTGGAAlSZIaYwCUJElqjAFQkiSpMamqoWsYjSQXAr8auo5VuAVw0dBFjJjXb9157daP12/9eP3Wj9dv3c32a3f7qtp6ZTsMgHNIkpOravHQdYyV12/dee3Wj9dv/Xj91o/Xb92N+dp5C1iSJKkxBkBJkqTGGADnlsOHLmDkvH7rzmu3frx+68frt368fututNfOPoCSJEmNsQVQkiSpMQZASZKkxhgAJUmSGmMAlCRJaowBUJIkqTH/H+sESGu4IVMIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "translate(u'good morning')\n",
    "\n",
    "translate(u'good morning my friend')\n",
    "\n",
    "translate(u'how was your day today')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "num_layers = 8\n",
    "d_model = 512\n",
    "dff = 512\n",
    "num_heads = 16\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.9217 Accuracy 0.0000\n",
      "Epoch 1 Loss 8.8423 Accuracy 0.0001\n",
      "Epoch 2 Batch 0 Loss 8.6598 Accuracy 0.0051\n",
      "Epoch 2 Loss 8.4074 Accuracy 0.0830\n",
      "Epoch 3 Batch 0 Loss 8.1125 Accuracy 0.1111\n",
      "Epoch 3 Loss 7.8745 Accuracy 0.1111\n",
      "Epoch 4 Batch 0 Loss 7.6037 Accuracy 0.1111\n",
      "Epoch 4 Loss 7.4272 Accuracy 0.1111\n",
      "Epoch 5 Batch 0 Loss 7.2486 Accuracy 0.1111\n",
      "Epoch 5 Loss 7.1120 Accuracy 0.1111\n",
      "Epoch 6 Batch 0 Loss 6.9680 Accuracy 0.1111\n",
      "Epoch 6 Loss 6.8966 Accuracy 0.1111\n",
      "Epoch 7 Batch 0 Loss 6.8160 Accuracy 0.1111\n",
      "Epoch 7 Loss 6.7254 Accuracy 0.1111\n",
      "Epoch 8 Batch 0 Loss 6.6335 Accuracy 0.1111\n",
      "Epoch 8 Loss 6.5634 Accuracy 0.1111\n",
      "Epoch 9 Batch 0 Loss 6.4879 Accuracy 0.1111\n",
      "Epoch 9 Loss 6.4086 Accuracy 0.1111\n",
      "Epoch 10 Batch 0 Loss 6.3131 Accuracy 0.1111\n",
      "Epoch 10 Loss 6.2474 Accuracy 0.1111\n",
      "Epoch 11 Batch 0 Loss 6.1357 Accuracy 0.1111\n",
      "Epoch 11 Loss 6.0423 Accuracy 0.1210\n",
      "Epoch 12 Batch 0 Loss 5.8823 Accuracy 0.1386\n",
      "Epoch 12 Loss 5.7697 Accuracy 0.1378\n",
      "Epoch 13 Batch 0 Loss 5.6464 Accuracy 0.1444\n",
      "Epoch 13 Loss 5.5264 Accuracy 0.1479\n",
      "Epoch 14 Batch 0 Loss 5.4105 Accuracy 0.1526\n",
      "Epoch 14 Loss 5.3054 Accuracy 0.1611\n",
      "Epoch 15 Batch 0 Loss 5.2239 Accuracy 0.1636\n",
      "Epoch 15 Loss 5.1146 Accuracy 0.1671\n",
      "Epoch 16 Batch 0 Loss 4.9927 Accuracy 0.1697\n",
      "Epoch 16 Loss 4.9604 Accuracy 0.1694\n",
      "Epoch 17 Batch 0 Loss 4.8635 Accuracy 0.1747\n",
      "Epoch 17 Loss 4.8106 Accuracy 0.1746\n",
      "Epoch 18 Batch 0 Loss 4.7561 Accuracy 0.1739\n",
      "Epoch 18 Loss 4.6923 Accuracy 0.1769\n",
      "Epoch 19 Batch 0 Loss 4.6265 Accuracy 0.1772\n",
      "Epoch 19 Loss 4.5751 Accuracy 0.1786\n",
      "Epoch 20 Batch 0 Loss 4.5034 Accuracy 0.1771\n",
      "Epoch 20 Loss 4.4643 Accuracy 0.1807\n",
      "Epoch 21 Batch 0 Loss 4.4341 Accuracy 0.1808\n",
      "Epoch 21 Loss 4.3708 Accuracy 0.1827\n",
      "Epoch 22 Batch 0 Loss 4.2735 Accuracy 0.1863\n",
      "Epoch 22 Loss 4.2772 Accuracy 0.1850\n",
      "Epoch 23 Batch 0 Loss 4.3095 Accuracy 0.1852\n",
      "Epoch 23 Loss 4.1864 Accuracy 0.1881\n",
      "Epoch 24 Batch 0 Loss 4.1427 Accuracy 0.1872\n",
      "Epoch 24 Loss 4.0954 Accuracy 0.1908\n",
      "Epoch 25 Batch 0 Loss 4.0067 Accuracy 0.1952\n",
      "Epoch 25 Loss 4.0101 Accuracy 0.1926\n",
      "Epoch 26 Batch 0 Loss 3.9632 Accuracy 0.1928\n",
      "Epoch 26 Loss 3.9155 Accuracy 0.1951\n",
      "Epoch 27 Batch 0 Loss 3.8589 Accuracy 0.1949\n",
      "Epoch 27 Loss 3.8318 Accuracy 0.1967\n",
      "Epoch 28 Batch 0 Loss 3.7783 Accuracy 0.1988\n",
      "Epoch 28 Loss 3.7430 Accuracy 0.1990\n",
      "Epoch 29 Batch 0 Loss 3.6468 Accuracy 0.2013\n",
      "Epoch 29 Loss 3.6552 Accuracy 0.2014\n",
      "Epoch 30 Batch 0 Loss 3.6178 Accuracy 0.2021\n",
      "Epoch 30 Loss 3.5773 Accuracy 0.2034\n",
      "Epoch 31 Batch 0 Loss 3.4732 Accuracy 0.2077\n",
      "Epoch 31 Loss 3.4912 Accuracy 0.2059\n",
      "Epoch 32 Batch 0 Loss 3.4452 Accuracy 0.2059\n",
      "Epoch 32 Loss 3.4124 Accuracy 0.2082\n",
      "Epoch 33 Batch 0 Loss 3.3760 Accuracy 0.2079\n",
      "Epoch 33 Loss 3.3357 Accuracy 0.2099\n",
      "Epoch 34 Batch 0 Loss 3.2416 Accuracy 0.2125\n",
      "Epoch 34 Loss 3.2549 Accuracy 0.2129\n",
      "Epoch 35 Batch 0 Loss 3.2145 Accuracy 0.2141\n",
      "Epoch 35 Loss 3.2007 Accuracy 0.2136\n",
      "Epoch 36 Batch 0 Loss 3.1802 Accuracy 0.2113\n",
      "Epoch 36 Loss 3.1101 Accuracy 0.2169\n",
      "Epoch 37 Batch 0 Loss 3.0276 Accuracy 0.2198\n",
      "Epoch 37 Loss 3.0349 Accuracy 0.2193\n",
      "Epoch 38 Batch 0 Loss 2.9316 Accuracy 0.2254\n",
      "Epoch 38 Loss 2.9623 Accuracy 0.2212\n",
      "Epoch 39 Batch 0 Loss 2.9413 Accuracy 0.2201\n",
      "Epoch 39 Loss 2.8961 Accuracy 0.2239\n",
      "Epoch 40 Batch 0 Loss 2.8621 Accuracy 0.2261\n",
      "Epoch 40 Loss 2.8274 Accuracy 0.2259\n",
      "Epoch 41 Batch 0 Loss 2.7652 Accuracy 0.2274\n",
      "Epoch 41 Loss 2.7583 Accuracy 0.2281\n",
      "Epoch 42 Batch 0 Loss 2.6876 Accuracy 0.2312\n",
      "Epoch 42 Loss 2.6882 Accuracy 0.2305\n",
      "Epoch 43 Batch 0 Loss 2.6557 Accuracy 0.2299\n",
      "Epoch 43 Loss 2.6251 Accuracy 0.2324\n",
      "Epoch 44 Batch 0 Loss 2.5885 Accuracy 0.2329\n",
      "Epoch 44 Loss 2.5525 Accuracy 0.2352\n",
      "Epoch 45 Batch 0 Loss 2.5046 Accuracy 0.2330\n",
      "Epoch 45 Loss 2.4832 Accuracy 0.2371\n",
      "Epoch 46 Batch 0 Loss 2.4711 Accuracy 0.2394\n",
      "Epoch 46 Loss 2.4187 Accuracy 0.2396\n",
      "Epoch 47 Batch 0 Loss 2.3363 Accuracy 0.2460\n",
      "Epoch 47 Loss 2.3586 Accuracy 0.2421\n",
      "Epoch 48 Batch 0 Loss 2.2819 Accuracy 0.2440\n",
      "Epoch 48 Loss 2.2902 Accuracy 0.2444\n",
      "Epoch 49 Batch 0 Loss 2.2105 Accuracy 0.2500\n",
      "Epoch 49 Loss 2.2254 Accuracy 0.2471\n",
      "Epoch 50 Batch 0 Loss 2.2039 Accuracy 0.2451\n",
      "Epoch 50 Loss 2.1667 Accuracy 0.2496\n",
      "Epoch 51 Batch 0 Loss 2.0998 Accuracy 0.2528\n",
      "Epoch 51 Loss 2.0989 Accuracy 0.2531\n",
      "Epoch 52 Batch 0 Loss 2.0208 Accuracy 0.2534\n",
      "Epoch 52 Loss 2.0425 Accuracy 0.2558\n",
      "Epoch 53 Batch 0 Loss 1.9727 Accuracy 0.2590\n",
      "Epoch 53 Loss 1.9866 Accuracy 0.2575\n",
      "Epoch 54 Batch 0 Loss 1.9635 Accuracy 0.2556\n",
      "Epoch 54 Loss 1.9324 Accuracy 0.2600\n",
      "Epoch 55 Batch 0 Loss 1.8788 Accuracy 0.2628\n",
      "Epoch 55 Loss 1.8573 Accuracy 0.2648\n",
      "Epoch 56 Batch 0 Loss 1.7953 Accuracy 0.2705\n",
      "Epoch 56 Loss 1.7990 Accuracy 0.2678\n",
      "Epoch 57 Batch 0 Loss 1.7140 Accuracy 0.2728\n",
      "Epoch 57 Loss 1.7400 Accuracy 0.2712\n",
      "Epoch 58 Batch 0 Loss 1.7243 Accuracy 0.2704\n",
      "Epoch 58 Loss 1.6794 Accuracy 0.2750\n",
      "Epoch 59 Batch 0 Loss 1.6353 Accuracy 0.2781\n",
      "Epoch 59 Loss 1.6370 Accuracy 0.2767\n",
      "Epoch 60 Batch 0 Loss 1.5750 Accuracy 0.2816\n",
      "Epoch 60 Loss 1.5704 Accuracy 0.2817\n",
      "Epoch 61 Batch 0 Loss 1.5611 Accuracy 0.2807\n",
      "Epoch 61 Loss 1.5184 Accuracy 0.2840\n",
      "Epoch 62 Batch 0 Loss 1.4816 Accuracy 0.2843\n",
      "Epoch 62 Loss 1.4722 Accuracy 0.2868\n",
      "Epoch 63 Batch 0 Loss 1.3987 Accuracy 0.2904\n",
      "Epoch 63 Loss 1.4204 Accuracy 0.2898\n",
      "Epoch 64 Batch 0 Loss 1.3535 Accuracy 0.2954\n",
      "Epoch 64 Loss 1.3743 Accuracy 0.2930\n",
      "Epoch 65 Batch 0 Loss 1.3310 Accuracy 0.2950\n",
      "Epoch 65 Loss 1.3209 Accuracy 0.2961\n",
      "Epoch 66 Batch 0 Loss 1.2839 Accuracy 0.2979\n",
      "Epoch 66 Loss 1.2713 Accuracy 0.2995\n",
      "Epoch 67 Batch 0 Loss 1.2571 Accuracy 0.2900\n",
      "Epoch 67 Loss 1.2303 Accuracy 0.3016\n",
      "Epoch 68 Batch 0 Loss 1.2254 Accuracy 0.3041\n",
      "Epoch 68 Loss 1.1849 Accuracy 0.3045\n",
      "Epoch 69 Batch 0 Loss 1.1434 Accuracy 0.3075\n",
      "Epoch 69 Loss 1.1342 Accuracy 0.3084\n",
      "Epoch 70 Batch 0 Loss 1.0754 Accuracy 0.3149\n",
      "Epoch 70 Loss 1.0906 Accuracy 0.3108\n",
      "Epoch 71 Batch 0 Loss 1.0060 Accuracy 0.3172\n",
      "Epoch 71 Loss 1.0525 Accuracy 0.3130\n",
      "Epoch 72 Batch 0 Loss 1.0163 Accuracy 0.3181\n",
      "Epoch 72 Loss 1.0164 Accuracy 0.3163\n",
      "Epoch 73 Batch 0 Loss 0.9654 Accuracy 0.3227\n",
      "Epoch 73 Loss 0.9811 Accuracy 0.3178\n",
      "Epoch 74 Batch 0 Loss 0.9467 Accuracy 0.3189\n",
      "Epoch 74 Loss 0.9393 Accuracy 0.3207\n",
      "Epoch 75 Batch 0 Loss 0.8983 Accuracy 0.3238\n",
      "Epoch 75 Loss 0.8996 Accuracy 0.3240\n",
      "Epoch 76 Batch 0 Loss 0.8755 Accuracy 0.3250\n",
      "Epoch 76 Loss 0.8725 Accuracy 0.3248\n",
      "Epoch 77 Batch 0 Loss 0.8490 Accuracy 0.3278\n",
      "Epoch 77 Loss 0.8380 Accuracy 0.3274\n",
      "Epoch 78 Batch 0 Loss 0.7961 Accuracy 0.3304\n",
      "Epoch 78 Loss 0.8114 Accuracy 0.3293\n",
      "Epoch 79 Batch 0 Loss 0.7610 Accuracy 0.3327\n",
      "Epoch 79 Loss 0.7807 Accuracy 0.3308\n",
      "Epoch 80 Batch 0 Loss 0.7516 Accuracy 0.3358\n",
      "Epoch 80 Loss 0.7540 Accuracy 0.3328\n",
      "Epoch 81 Batch 0 Loss 0.7084 Accuracy 0.3357\n",
      "Epoch 81 Loss 0.7243 Accuracy 0.3342\n",
      "Epoch 82 Batch 0 Loss 0.6962 Accuracy 0.3380\n",
      "Epoch 82 Loss 0.6997 Accuracy 0.3357\n",
      "Epoch 83 Batch 0 Loss 0.6685 Accuracy 0.3409\n",
      "Epoch 83 Loss 0.6711 Accuracy 0.3377\n",
      "Epoch 84 Batch 0 Loss 0.6389 Accuracy 0.3407\n",
      "Epoch 84 Loss 0.6501 Accuracy 0.3390\n",
      "Epoch 85 Batch 0 Loss 0.5952 Accuracy 0.3504\n",
      "Epoch 85 Loss 0.6246 Accuracy 0.3407\n",
      "Epoch 86 Batch 0 Loss 0.6099 Accuracy 0.3469\n",
      "Epoch 86 Loss 0.6044 Accuracy 0.3422\n",
      "Epoch 87 Batch 0 Loss 0.5612 Accuracy 0.3471\n",
      "Epoch 87 Loss 0.5858 Accuracy 0.3425\n",
      "Epoch 88 Batch 0 Loss 0.5475 Accuracy 0.3472\n",
      "Epoch 88 Loss 0.5756 Accuracy 0.3433\n",
      "Epoch 89 Batch 0 Loss 0.5430 Accuracy 0.3422\n",
      "Epoch 89 Loss 0.5497 Accuracy 0.3446\n",
      "Epoch 90 Batch 0 Loss 0.5507 Accuracy 0.3439\n",
      "Epoch 90 Loss 0.5331 Accuracy 0.3459\n",
      "Epoch 91 Batch 0 Loss 0.5117 Accuracy 0.3460\n",
      "Epoch 91 Loss 0.5251 Accuracy 0.3456\n",
      "Epoch 92 Batch 0 Loss 0.4931 Accuracy 0.3484\n",
      "Epoch 92 Loss 0.5108 Accuracy 0.3457\n",
      "Epoch 93 Batch 0 Loss 0.4704 Accuracy 0.3530\n",
      "Epoch 93 Loss 0.4913 Accuracy 0.3475\n",
      "Epoch 94 Batch 0 Loss 0.4679 Accuracy 0.3477\n",
      "Epoch 94 Loss 0.4809 Accuracy 0.3477\n",
      "Epoch 95 Batch 0 Loss 0.4538 Accuracy 0.3462\n",
      "Epoch 95 Loss 0.4731 Accuracy 0.3474\n",
      "Epoch 96 Batch 0 Loss 0.4442 Accuracy 0.3524\n",
      "Epoch 96 Loss 0.4616 Accuracy 0.3486\n",
      "Epoch 97 Batch 0 Loss 0.4253 Accuracy 0.3544\n",
      "Epoch 97 Loss 0.4456 Accuracy 0.3493\n",
      "Epoch 98 Batch 0 Loss 0.4130 Accuracy 0.3574\n",
      "Epoch 98 Loss 0.4341 Accuracy 0.3496\n",
      "Epoch 99 Batch 0 Loss 0.3957 Accuracy 0.3653\n",
      "Epoch 99 Loss 0.4288 Accuracy 0.3505\n",
      "Epoch 100 Batch 0 Loss 0.4016 Accuracy 0.3563\n",
      "Epoch 100 Loss 0.4207 Accuracy 0.3505\n",
      "Epoch 101 Batch 0 Loss 0.4124 Accuracy 0.3557\n",
      "Epoch 101 Loss 0.4133 Accuracy 0.3511\n",
      "Epoch 102 Batch 0 Loss 0.3763 Accuracy 0.3641\n",
      "Epoch 102 Loss 0.4058 Accuracy 0.3512\n",
      "Epoch 103 Batch 0 Loss 0.3857 Accuracy 0.3537\n",
      "Epoch 103 Loss 0.4110 Accuracy 0.3505\n",
      "Epoch 104 Batch 0 Loss 0.3957 Accuracy 0.3564\n",
      "Epoch 104 Loss 0.4050 Accuracy 0.3512\n",
      "Epoch 105 Batch 0 Loss 0.3866 Accuracy 0.3511\n",
      "Epoch 105 Loss 0.4003 Accuracy 0.3511\n",
      "Epoch 106 Batch 0 Loss 0.3873 Accuracy 0.3481\n",
      "Epoch 106 Loss 0.3851 Accuracy 0.3527\n",
      "Epoch 107 Batch 0 Loss 0.3594 Accuracy 0.3533\n",
      "Epoch 107 Loss 0.3816 Accuracy 0.3527\n",
      "Epoch 108 Batch 0 Loss 0.3580 Accuracy 0.3550\n",
      "Epoch 108 Loss 0.3821 Accuracy 0.3514\n",
      "Epoch 109 Batch 0 Loss 0.3596 Accuracy 0.3548\n",
      "Epoch 109 Loss 0.3765 Accuracy 0.3525\n",
      "Epoch 110 Batch 0 Loss 0.3595 Accuracy 0.3512\n",
      "Epoch 110 Loss 0.3735 Accuracy 0.3517\n",
      "Epoch 111 Batch 0 Loss 0.3312 Accuracy 0.3669\n",
      "Epoch 111 Loss 0.3663 Accuracy 0.3535\n",
      "Epoch 112 Batch 0 Loss 0.3317 Accuracy 0.3614\n",
      "Epoch 112 Loss 0.3614 Accuracy 0.3535\n",
      "Epoch 113 Batch 0 Loss 0.3354 Accuracy 0.3600\n",
      "Epoch 113 Loss 0.3608 Accuracy 0.3530\n",
      "Epoch 114 Batch 0 Loss 0.3276 Accuracy 0.3588\n",
      "Epoch 114 Loss 0.3546 Accuracy 0.3536\n",
      "Epoch 115 Batch 0 Loss 0.3299 Accuracy 0.3582\n",
      "Epoch 115 Loss 0.3602 Accuracy 0.3529\n",
      "Epoch 116 Batch 0 Loss 0.3366 Accuracy 0.3599\n",
      "Epoch 116 Loss 0.3667 Accuracy 0.3528\n",
      "Epoch 117 Batch 0 Loss 0.3271 Accuracy 0.3581\n",
      "Epoch 117 Loss 0.3531 Accuracy 0.3530\n",
      "Epoch 118 Batch 0 Loss 0.3085 Accuracy 0.3669\n",
      "Epoch 118 Loss 0.3489 Accuracy 0.3546\n",
      "Epoch 119 Batch 0 Loss 0.3227 Accuracy 0.3559\n",
      "Epoch 119 Loss 0.3501 Accuracy 0.3532\n",
      "Epoch 120 Batch 0 Loss 0.3263 Accuracy 0.3558\n",
      "Epoch 120 Loss 0.3481 Accuracy 0.3536\n",
      "Epoch 121 Batch 0 Loss 0.3128 Accuracy 0.3622\n",
      "Epoch 121 Loss 0.3470 Accuracy 0.3536\n",
      "Epoch 122 Batch 0 Loss 0.3242 Accuracy 0.3544\n",
      "Epoch 122 Loss 0.3421 Accuracy 0.3538\n",
      "Epoch 123 Batch 0 Loss 0.3285 Accuracy 0.3566\n",
      "Epoch 123 Loss 0.3436 Accuracy 0.3546\n",
      "Epoch 124 Batch 0 Loss 0.3116 Accuracy 0.3598\n",
      "Epoch 124 Loss 0.3405 Accuracy 0.3546\n",
      "Epoch 125 Batch 0 Loss 0.3229 Accuracy 0.3645\n",
      "Epoch 125 Loss 0.3386 Accuracy 0.3540\n",
      "Epoch 126 Batch 0 Loss 0.3099 Accuracy 0.3605\n",
      "Epoch 126 Loss 0.3364 Accuracy 0.3535\n",
      "Epoch 127 Batch 0 Loss 0.2942 Accuracy 0.3647\n",
      "Epoch 127 Loss 0.3351 Accuracy 0.3547\n",
      "Epoch 128 Batch 0 Loss 0.3097 Accuracy 0.3595\n",
      "Epoch 128 Loss 0.3301 Accuracy 0.3542\n",
      "Epoch 129 Batch 0 Loss 0.2891 Accuracy 0.3608\n",
      "Epoch 129 Loss 0.3263 Accuracy 0.3547\n",
      "Epoch 130 Batch 0 Loss 0.3059 Accuracy 0.3563\n",
      "Epoch 130 Loss 0.3307 Accuracy 0.3547\n",
      "Epoch 131 Batch 0 Loss 0.2954 Accuracy 0.3635\n",
      "Epoch 131 Loss 0.3297 Accuracy 0.3551\n",
      "Epoch 132 Batch 0 Loss 0.2915 Accuracy 0.3645\n",
      "Epoch 132 Loss 0.3300 Accuracy 0.3550\n",
      "Epoch 133 Batch 0 Loss 0.3033 Accuracy 0.3587\n",
      "Epoch 133 Loss 0.3309 Accuracy 0.3548\n",
      "Epoch 134 Batch 0 Loss 0.2930 Accuracy 0.3671\n",
      "Epoch 134 Loss 0.3303 Accuracy 0.3547\n",
      "Epoch 135 Batch 0 Loss 0.2901 Accuracy 0.3573\n",
      "Epoch 135 Loss 0.3294 Accuracy 0.3545\n",
      "Epoch 136 Batch 0 Loss 0.2875 Accuracy 0.3663\n",
      "Epoch 136 Loss 0.3299 Accuracy 0.3553\n",
      "Epoch 137 Batch 0 Loss 0.3106 Accuracy 0.3582\n",
      "Epoch 137 Loss 0.3253 Accuracy 0.3549\n",
      "Epoch 138 Batch 0 Loss 0.2828 Accuracy 0.3633\n",
      "Epoch 138 Loss 0.3253 Accuracy 0.3554\n",
      "Epoch 139 Batch 0 Loss 0.2807 Accuracy 0.3704\n",
      "Epoch 139 Loss 0.3241 Accuracy 0.3548\n",
      "Epoch 140 Batch 0 Loss 0.2946 Accuracy 0.3573\n",
      "Epoch 140 Loss 0.3207 Accuracy 0.3558\n",
      "Epoch 141 Batch 0 Loss 0.2753 Accuracy 0.3647\n",
      "Epoch 141 Loss 0.3188 Accuracy 0.3558\n",
      "Epoch 142 Batch 0 Loss 0.2852 Accuracy 0.3607\n",
      "Epoch 142 Loss 0.3230 Accuracy 0.3554\n",
      "Epoch 143 Batch 0 Loss 0.2996 Accuracy 0.3625\n",
      "Epoch 143 Loss 0.3266 Accuracy 0.3549\n",
      "Epoch 144 Batch 0 Loss 0.2856 Accuracy 0.3627\n",
      "Epoch 144 Loss 0.3248 Accuracy 0.3553\n",
      "Epoch 145 Batch 0 Loss 0.2817 Accuracy 0.3620\n",
      "Epoch 145 Loss 0.3255 Accuracy 0.3554\n",
      "Epoch 146 Batch 0 Loss 0.2735 Accuracy 0.3669\n",
      "Epoch 146 Loss 0.3188 Accuracy 0.3554\n",
      "Epoch 147 Batch 0 Loss 0.2793 Accuracy 0.3651\n",
      "Epoch 147 Loss 0.3165 Accuracy 0.3551\n",
      "Epoch 148 Batch 0 Loss 0.3009 Accuracy 0.3592\n",
      "Epoch 148 Loss 0.3164 Accuracy 0.3553\n",
      "Epoch 149 Batch 0 Loss 0.2828 Accuracy 0.3612\n",
      "Epoch 149 Loss 0.3170 Accuracy 0.3555\n",
      "Epoch 150 Batch 0 Loss 0.2988 Accuracy 0.3588\n",
      "Epoch 150 Loss 0.3210 Accuracy 0.3551\n",
      "Epoch 151 Batch 0 Loss 0.2977 Accuracy 0.3619\n",
      "Epoch 151 Loss 0.3211 Accuracy 0.3554\n",
      "Epoch 152 Batch 0 Loss 0.2941 Accuracy 0.3656\n",
      "Epoch 152 Loss 0.3189 Accuracy 0.3555\n",
      "Epoch 153 Batch 0 Loss 0.2906 Accuracy 0.3633\n",
      "Epoch 153 Loss 0.3167 Accuracy 0.3550\n",
      "Epoch 154 Batch 0 Loss 0.2667 Accuracy 0.3677\n",
      "Epoch 154 Loss 0.3172 Accuracy 0.3551\n",
      "Epoch 155 Batch 0 Loss 0.2738 Accuracy 0.3631\n",
      "Epoch 155 Loss 0.3149 Accuracy 0.3554\n",
      "Epoch 156 Batch 0 Loss 0.2854 Accuracy 0.3628\n",
      "Epoch 156 Loss 0.3160 Accuracy 0.3558\n",
      "Epoch 157 Batch 0 Loss 0.2905 Accuracy 0.3621\n",
      "Epoch 157 Loss 0.3199 Accuracy 0.3549\n",
      "Epoch 158 Batch 0 Loss 0.2947 Accuracy 0.3633\n",
      "Epoch 158 Loss 0.3165 Accuracy 0.3549\n",
      "Epoch 159 Batch 0 Loss 0.2809 Accuracy 0.3624\n",
      "Epoch 159 Loss 0.3184 Accuracy 0.3548\n",
      "Epoch 160 Batch 0 Loss 0.2858 Accuracy 0.3651\n",
      "Epoch 160 Loss 0.3176 Accuracy 0.3557\n",
      "Epoch 161 Batch 0 Loss 0.2869 Accuracy 0.3576\n",
      "Epoch 161 Loss 0.3144 Accuracy 0.3554\n",
      "Epoch 162 Batch 0 Loss 0.2796 Accuracy 0.3585\n",
      "Epoch 162 Loss 0.3147 Accuracy 0.3549\n",
      "Epoch 163 Batch 0 Loss 0.2704 Accuracy 0.3643\n",
      "Epoch 163 Loss 0.3161 Accuracy 0.3558\n",
      "Epoch 164 Batch 0 Loss 0.2949 Accuracy 0.3589\n",
      "Epoch 164 Loss 0.3147 Accuracy 0.3552\n",
      "Epoch 165 Batch 0 Loss 0.2885 Accuracy 0.3559\n",
      "Epoch 165 Loss 0.3179 Accuracy 0.3548\n",
      "Epoch 166 Batch 0 Loss 0.2720 Accuracy 0.3617\n",
      "Epoch 166 Loss 0.3138 Accuracy 0.3561\n",
      "Epoch 167 Batch 0 Loss 0.2759 Accuracy 0.3607\n",
      "Epoch 167 Loss 0.3084 Accuracy 0.3562\n",
      "Epoch 168 Batch 0 Loss 0.2822 Accuracy 0.3604\n",
      "Epoch 168 Loss 0.3125 Accuracy 0.3553\n",
      "Epoch 169 Batch 0 Loss 0.2800 Accuracy 0.3618\n",
      "Epoch 169 Loss 0.3194 Accuracy 0.3552\n",
      "Epoch 170 Batch 0 Loss 0.2882 Accuracy 0.3585\n",
      "Epoch 170 Loss 0.3243 Accuracy 0.3541\n",
      "Epoch 171 Batch 0 Loss 0.3032 Accuracy 0.3555\n",
      "Epoch 171 Loss 0.3171 Accuracy 0.3553\n",
      "Epoch 172 Batch 0 Loss 0.2784 Accuracy 0.3608\n",
      "Epoch 172 Loss 0.3172 Accuracy 0.3546\n",
      "Epoch 173 Batch 0 Loss 0.2776 Accuracy 0.3608\n",
      "Epoch 173 Loss 0.3161 Accuracy 0.3549\n",
      "Epoch 174 Batch 0 Loss 0.3016 Accuracy 0.3553\n",
      "Epoch 174 Loss 0.3127 Accuracy 0.3556\n",
      "Epoch 175 Batch 0 Loss 0.2620 Accuracy 0.3682\n",
      "Epoch 175 Loss 0.3089 Accuracy 0.3563\n",
      "Epoch 176 Batch 0 Loss 0.2720 Accuracy 0.3634\n",
      "Epoch 176 Loss 0.3108 Accuracy 0.3560\n",
      "Epoch 177 Batch 0 Loss 0.2686 Accuracy 0.3651\n",
      "Epoch 177 Loss 0.3088 Accuracy 0.3559\n",
      "Epoch 178 Batch 0 Loss 0.2648 Accuracy 0.3683\n",
      "Epoch 178 Loss 0.3057 Accuracy 0.3557\n",
      "Epoch 179 Batch 0 Loss 0.2669 Accuracy 0.3664\n",
      "Epoch 179 Loss 0.3073 Accuracy 0.3560\n",
      "Epoch 180 Batch 0 Loss 0.2800 Accuracy 0.3660\n",
      "Epoch 180 Loss 0.3132 Accuracy 0.3558\n",
      "Epoch 181 Batch 0 Loss 0.2747 Accuracy 0.3627\n",
      "Epoch 181 Loss 0.3142 Accuracy 0.3552\n",
      "Epoch 182 Batch 0 Loss 0.2756 Accuracy 0.3655\n",
      "Epoch 182 Loss 0.3080 Accuracy 0.3558\n",
      "Epoch 183 Batch 0 Loss 0.2868 Accuracy 0.3674\n",
      "Epoch 183 Loss 0.3054 Accuracy 0.3562\n",
      "Epoch 184 Batch 0 Loss 0.2794 Accuracy 0.3601\n",
      "Epoch 184 Loss 0.3084 Accuracy 0.3560\n",
      "Epoch 185 Batch 0 Loss 0.2948 Accuracy 0.3607\n",
      "Epoch 185 Loss 0.3128 Accuracy 0.3557\n",
      "Epoch 186 Batch 0 Loss 0.2742 Accuracy 0.3631\n",
      "Epoch 186 Loss 0.3079 Accuracy 0.3563\n",
      "Epoch 187 Batch 0 Loss 0.2627 Accuracy 0.3653\n",
      "Epoch 187 Loss 0.3123 Accuracy 0.3554\n",
      "Epoch 188 Batch 0 Loss 0.2603 Accuracy 0.3632\n",
      "Epoch 188 Loss 0.3104 Accuracy 0.3554\n",
      "Epoch 189 Batch 0 Loss 0.2789 Accuracy 0.3612\n",
      "Epoch 189 Loss 0.3138 Accuracy 0.3561\n",
      "Epoch 190 Batch 0 Loss 0.2746 Accuracy 0.3632\n",
      "Epoch 190 Loss 0.3128 Accuracy 0.3551\n",
      "Epoch 191 Batch 0 Loss 0.2860 Accuracy 0.3619\n",
      "Epoch 191 Loss 0.3111 Accuracy 0.3559\n",
      "Epoch 192 Batch 0 Loss 0.2693 Accuracy 0.3613\n",
      "Epoch 192 Loss 0.3075 Accuracy 0.3555\n",
      "Epoch 193 Batch 0 Loss 0.2738 Accuracy 0.3662\n",
      "Epoch 193 Loss 0.3084 Accuracy 0.3557\n",
      "Epoch 194 Batch 0 Loss 0.2875 Accuracy 0.3587\n",
      "Epoch 194 Loss 0.3146 Accuracy 0.3554\n",
      "Epoch 195 Batch 0 Loss 0.2881 Accuracy 0.3600\n",
      "Epoch 195 Loss 0.3138 Accuracy 0.3547\n",
      "Epoch 196 Batch 0 Loss 0.2709 Accuracy 0.3650\n",
      "Epoch 196 Loss 0.3113 Accuracy 0.3559\n",
      "Epoch 197 Batch 0 Loss 0.2986 Accuracy 0.3586\n",
      "Epoch 197 Loss 0.3133 Accuracy 0.3551\n",
      "Epoch 198 Batch 0 Loss 0.2802 Accuracy 0.3607\n",
      "Epoch 198 Loss 0.3087 Accuracy 0.3555\n",
      "Epoch 199 Batch 0 Loss 0.2601 Accuracy 0.3695\n",
      "Epoch 199 Loss 0.3078 Accuracy 0.3550\n",
      "Epoch 200 Batch 0 Loss 0.2716 Accuracy 0.3610\n",
      "Epoch 200 Loss 0.3087 Accuracy 0.3558\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'доброе', 'утро']\n"
     ]
    }
   ],
   "source": [
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: how was your day today\n",
      "Predicted translation: ['<start>', 'где', 'живи', 'как']\n"
     ]
    }
   ],
   "source": [
    "translate(u'how was your day today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
