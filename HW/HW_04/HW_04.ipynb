{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема “Анализ тональности” \n",
    "#### Задание\n",
    "В качестве заготовки для задания прогоним часть 2ого домашнего задания. Нам необходимо получить разреженные матрицы, используя CountVectorizer, TfidfVectorizer для 'tweet_stemmed' и 'tweet_lemmatized' столбцов (4 матрицы).\n",
    "\n",
    "Задание 1.\n",
    "Построим модель LogisticRegression, используя Bag-of-Words признаки для столбца combine_df['tweet_stemmed']. \n",
    "- Поделим Bag-of-Words признаки на train, test (train заканчивается на 31962 строке combine_df)\n",
    "- Ответами является столбец train_df['label']\n",
    "- Рассчитаем predict_proba, приведем prediction в в бинарный вид: если предсказание >= 0.3 то 1, иначе 0, тип заменим на int\n",
    "- Рассчитаем f1_score \n",
    "\n",
    "Повторим аналогично для столбца combine_df['tweet_lemmatized'].\n",
    "\n",
    "Задание 2.\n",
    "Построим модель LogisticRegression, используя TF-IDF признаки для столбца combine_df['tweet_stemmed']. \n",
    "- Поделим TF-IDF признаки на train, test (train заканчивается на 31962 строке combine_df)\n",
    "- Ответами является столбец train_df['label']\n",
    "- Рассчитаем predict_proba, приведем prediction в в бинарный вид: если предсказание >= 0.3 то 1, иначе 0, тип заменим на int\n",
    "- Рассчитаем f1_score \n",
    "\n",
    "Повторим аналогично для столбца combine_df['tweet_lemmatized'].\n",
    "\n",
    "Задание 3.\n",
    "Выведите результаты f1-score всех моделей, сделайте вывод.\n",
    "\n",
    "Задание 4.\n",
    "Теперь перейдем к визуализации. Посмотрим, какие слова являются наиболее популярные в датасете с помощью облака слов (WordCloud).\n",
    "Облако слов - это визуализация, в которой наиболее частые слова большого размера, а менее частые слова меньшего размера.\n",
    "- объединим слова в одну строку\n",
    "- создадим словарь частот слов с помощью collections.Counter\n",
    "- нарисуем облако слов с частотами слов с помощью WordCloud.generate_from_frequencies()\n",
    "- используем nltk.corpus.stopwords как параметр stopwords, чтобы убрать \"мусорные\" частотные слова\n",
    "\n",
    "Задание 5.\n",
    "Теперь отобразим облако слов для отзывов, не содержащих токсичных комментариев (combine_df['label'] == 0). \n",
    "\n",
    "Задание 6.\n",
    "Теперь отобразим облако слов для отзывов, содержащих токсичные комментарии (combine_df['label'] == 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    !pip install -U wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "PREP_DATA = '../data/prep_tweets.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим подготовленный датасет твиттов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = pd.read_pickle(PREP_DATA)\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка и разбивка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_INDEX = 31962\n",
    "VAl_PART = 0.3\n",
    "\n",
    "# получим тест и трайн без исопользования индекса - по наличию label\n",
    "df_train = df_prep.loc[df_prep.label.notna(), ['tweet_stemmed', 'tweet_lemmatized', 'label']]\n",
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.929854\n",
       "1.0    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нужна стратифицированная выборка\n",
    "df_train.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('label', axis=1)\n",
    "Y = df_train.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=VAl_PART,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_bag_of_words(vectorizer: object, \n",
    "                       data: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    _Промежуточная функция для получения bag_of_words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pd.Series\n",
    "        Серия со списками токенов\n",
    "        \n",
    "    vectorizer: object\n",
    "        Объект векторайзера Bag-of-words.\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Разреженная матрица токенизиорованных эмбеддингов для использования в моделях.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    bag_of_words = vectorizer.fit_transform(data.apply(' '.join))\n",
    "    \n",
    "    # Отобразим Bag-of-Words модель как DataFrame\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return pd.DataFrame(bag_of_words.toarray(), columns = feature_names).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(data: pd.Series,\n",
    "                  vectorizer: callable,\n",
    "                  parameters: dict = {'max_df': 0.9,\n",
    "                                      'max_features': 1000,\n",
    "                                      'stop_words': 'english'}) -> pd.DataFrame:\n",
    "    \n",
    "    model = vectorizer(**parameters)\n",
    "    return _make_bag_of_words(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_CV = make_embedding(data=X_train['tweet_stemmed'], vectorizer=CountVectorizer)\n",
    "X_test_stem_CV = make_embedding(data=X_test['tweet_stemmed'], vectorizer=CountVectorizer)\n",
    "\n",
    "X_train_lemm_CV = make_embedding(data=X_train['tweet_lemmatized'], vectorizer=CountVectorizer)\n",
    "X_test_lemm_CV = make_embedding(data=X_test['tweet_lemmatized'], vectorizer=CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_TF = make_embedding(data=X_train['tweet_stemmed'], vectorizer=TfidfVectorizer)\n",
    "X_train_lemm_TF = make_embedding(data=X_train['tweet_lemmatized'], vectorizer=TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тренируем модели и вычисляем скор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чуть поправил функцию расчета скора\n",
    "def eval_model(model: object,\n",
    "               X_train: pd.DataFrame,\n",
    "               y_train: pd.Series,\n",
    "               X_test: pd.DataFrame,\n",
    "               y_test: pd.Series,\n",
    "               eval_metric: callable = f1_score) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Оценка качеcтва модели.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: callabe\n",
    "        Инициализированная модель для обучения.\n",
    "    \n",
    "    X_train, X_test: pandas.DataFrame\n",
    "    \n",
    "    Разреженные матрицы токенизированных эмбеддингов.\n",
    "    Получение из сплитов в функции get_embedding().\n",
    "    \n",
    "    y_train, y_test:\n",
    "    \n",
    "    Размеченные сплиты меток классов.\n",
    "    \n",
    "    eval_metric: callable\n",
    "        Метрика качества.\n",
    "        Опциональный параметр, по умолчанию используется f1_score.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        Расчетное качество по заданной метрике\n",
    "    \"\"\"\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    pred_prob = model.predict_proba(X_test)\n",
    "    y_pred = np.where(pred_prob[:,1]>0.3, 1,0)\n",
    "    score = eval_metric(y_test, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
